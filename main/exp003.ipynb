{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"../input\")\n",
    "\n",
    "train_df = pd.read_parquet(input_path / \"train.parquet\")\n",
    "test_df = pd.read_parquet(input_path / \"test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSLEの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval_rmsle(preds, data):\n",
    "    y_true = data.get_label()\n",
    "    preds = np.clip(preds, 0, None)  # 0より小さい値を0に置換\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, preds))\n",
    "    return 'RMSLE', rmsle, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>2012-12-31 19:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>2012-12-31 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>2012-12-31 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>2012-12-31 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>2012-12-31 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>65</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  season  holiday  workingday  weather   temp  \\\n",
       "0      2011-01-01 00:00:00       1        0           0        1   9.84   \n",
       "1      2011-01-01 01:00:00       1        0           0        1   9.02   \n",
       "2      2011-01-01 02:00:00       1        0           0        1   9.02   \n",
       "3      2011-01-01 03:00:00       1        0           0        1   9.84   \n",
       "4      2011-01-01 04:00:00       1        0           0        1   9.84   \n",
       "...                    ...     ...      ...         ...      ...    ...   \n",
       "17374  2012-12-31 19:00:00       1        0           1        2  10.66   \n",
       "17375  2012-12-31 20:00:00       1        0           1        2  10.66   \n",
       "17376  2012-12-31 21:00:00       1        0           1        1  10.66   \n",
       "17377  2012-12-31 22:00:00       1        0           1        1  10.66   \n",
       "17378  2012-12-31 23:00:00       1        0           1        1  10.66   \n",
       "\n",
       "        atemp  humidity  windspeed  count  \n",
       "0      14.395        81     0.0000   16.0  \n",
       "1      13.635        80     0.0000   40.0  \n",
       "2      13.635        80     0.0000   32.0  \n",
       "3      14.395        75     0.0000   13.0  \n",
       "4      14.395        75     0.0000    1.0  \n",
       "...       ...       ...        ...    ...  \n",
       "17374  12.880        60    11.0014    NaN  \n",
       "17375  12.880        60    11.0014    NaN  \n",
       "17376  12.880        60    11.0014    NaN  \n",
       "17377  13.635        56     8.9981    NaN  \n",
       "17378  13.635        65     8.9981    NaN  \n",
       "\n",
       "[17379 rows x 10 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0, sort=False).reset_index(drop=True)\n",
    "df = df.drop([\"casual\", \"registered\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>60</td>\n",
       "      <td>11.0014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>65</td>\n",
       "      <td>8.9981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  holiday  workingday  weather   temp   atemp  humidity  \\\n",
       "0           1        0           0        1   9.84  14.395        81   \n",
       "1           1        0           0        1   9.02  13.635        80   \n",
       "2           1        0           0        1   9.02  13.635        80   \n",
       "3           1        0           0        1   9.84  14.395        75   \n",
       "4           1        0           0        1   9.84  14.395        75   \n",
       "...       ...      ...         ...      ...    ...     ...       ...   \n",
       "17374       1        0           1        2  10.66  12.880        60   \n",
       "17375       1        0           1        2  10.66  12.880        60   \n",
       "17376       1        0           1        1  10.66  12.880        60   \n",
       "17377       1        0           1        1  10.66  13.635        56   \n",
       "17378       1        0           1        1  10.66  13.635        65   \n",
       "\n",
       "       windspeed  count  year  month  day  hour  dayofweek  \n",
       "0         0.0000   16.0  2011      1    1     0          5  \n",
       "1         0.0000   40.0  2011      1    1     1          5  \n",
       "2         0.0000   32.0  2011      1    1     2          5  \n",
       "3         0.0000   13.0  2011      1    1     3          5  \n",
       "4         0.0000    1.0  2011      1    1     4          5  \n",
       "...          ...    ...   ...    ...  ...   ...        ...  \n",
       "17374    11.0014    NaN  2012     12   31    19          0  \n",
       "17375    11.0014    NaN  2012     12   31    20          0  \n",
       "17376    11.0014    NaN  2012     12   31    21          0  \n",
       "17377     8.9981    NaN  2012     12   31    22          0  \n",
       "17378     8.9981    NaN  2012     12   31    23          0  \n",
       "\n",
       "[17379 rows x 14 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime = pd.to_datetime(df[\"datetime\"])\n",
    "df[\"year\"] = datetime.dt.year\n",
    "df[\"month\"] = datetime.dt.month\n",
    "df[\"day\"] = datetime.dt.day\n",
    "df[\"hour\"] = datetime.dt.hour\n",
    "df[\"dayofweek\"] = datetime.dt.day_name()\n",
    "df[\"dayofweek\"] = df[\"dayofweek\"].map({\"Monday\": 0, \"Tuesday\": 1, \"Wednesday\": 2, \"Thursday\": 3, \"Friday\": 4, \"Saturday\": 5, \"Sunday\": 6})\n",
    "df = df.drop(\"datetime\", axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[~df[\"count\"].isnull()].reset_index(drop=True)\n",
    "test_df = df[df[\"count\"].isnull()].drop(\"count\", axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, model_path):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_rmsles = []\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(df)):\n",
    "        print(f\"start training for fold {fold}\")\n",
    "\n",
    "        X_train = df.iloc[train_index].drop([\"count\"], axis=1)\n",
    "        y_train = df.iloc[train_index][\"count\"]\n",
    "\n",
    "        X_valid = df.iloc[valid_index].drop([\"count\"], axis=1)\n",
    "        y_valid = df.iloc[valid_index][\"count\"]\n",
    "\n",
    "        print(\"start training\")\n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"seed\": 42,\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"num_leaves\": 32,\n",
    "        }\n",
    "\n",
    "        train_set = lgb.Dataset(X_train, y_train)\n",
    "        valid_set = lgb.Dataset(X_valid, y_valid, reference=train_set)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_set,\n",
    "            valid_sets=[train_set, valid_set],\n",
    "            num_boost_round=10000,\n",
    "            feval=feval_rmsle,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
    "                lgb.log_evaluation(period=10)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f\"predict valid for fold {fold}\")\n",
    "        y_pred = model.predict(X_valid)\n",
    "        y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "        fold_rmsles.append(np.sqrt(mean_squared_log_error(y_valid, y_pred)))\n",
    "\n",
    "        print(f\"save model for fold {fold}\")\n",
    "        model.save_model(model_path / f\"model_fold{fold+1:03d}.bin\", num_iteration=model.best_iteration)\n",
    "\n",
    "    return sum(fold_rmsles) / len(fold_rmsles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training for fold 0\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 8708, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 191.584750\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 28078.3\ttraining's RMSLE: 1.51114\tvalid_1's l2: 28343.7\tvalid_1's RMSLE: 1.53408\n",
      "[20]\ttraining's l2: 24177.7\ttraining's RMSLE: 1.46235\tvalid_1's l2: 24438.5\tvalid_1's RMSLE: 1.48548\n",
      "[30]\ttraining's l2: 20971.1\ttraining's RMSLE: 1.41699\tvalid_1's l2: 21208.1\tvalid_1's RMSLE: 1.44028\n",
      "[40]\ttraining's l2: 18289.6\ttraining's RMSLE: 1.37415\tvalid_1's l2: 18495.2\tvalid_1's RMSLE: 1.39761\n",
      "[50]\ttraining's l2: 16046.9\ttraining's RMSLE: 1.3336\tvalid_1's l2: 16222.6\tvalid_1's RMSLE: 1.35723\n",
      "[60]\ttraining's l2: 14170\ttraining's RMSLE: 1.29501\tvalid_1's l2: 14296.2\tvalid_1's RMSLE: 1.31869\n",
      "[70]\ttraining's l2: 12600.6\ttraining's RMSLE: 1.25811\tvalid_1's l2: 12683.1\tvalid_1's RMSLE: 1.2818\n",
      "[80]\ttraining's l2: 11274.4\ttraining's RMSLE: 1.22234\tvalid_1's l2: 11324.7\tvalid_1's RMSLE: 1.24599\n",
      "[90]\ttraining's l2: 10109.7\ttraining's RMSLE: 1.18834\tvalid_1's l2: 10151\tvalid_1's RMSLE: 1.2121\n",
      "[100]\ttraining's l2: 9088.57\ttraining's RMSLE: 1.15508\tvalid_1's l2: 9122.22\tvalid_1's RMSLE: 1.17901\n",
      "[110]\ttraining's l2: 8135.75\ttraining's RMSLE: 1.12106\tvalid_1's l2: 8173.24\tvalid_1's RMSLE: 1.14492\n",
      "[120]\ttraining's l2: 7316.88\ttraining's RMSLE: 1.08737\tvalid_1's l2: 7359.09\tvalid_1's RMSLE: 1.11102\n",
      "[130]\ttraining's l2: 6641.58\ttraining's RMSLE: 1.0546\tvalid_1's l2: 6690.52\tvalid_1's RMSLE: 1.07797\n",
      "[140]\ttraining's l2: 6018.57\ttraining's RMSLE: 1.02213\tvalid_1's l2: 6073.62\tvalid_1's RMSLE: 1.04525\n",
      "[150]\ttraining's l2: 5504.98\ttraining's RMSLE: 0.990538\tvalid_1's l2: 5562.34\tvalid_1's RMSLE: 1.01337\n",
      "[160]\ttraining's l2: 5065.49\ttraining's RMSLE: 0.960607\tvalid_1's l2: 5120.08\tvalid_1's RMSLE: 0.983117\n",
      "[170]\ttraining's l2: 4685.18\ttraining's RMSLE: 0.931563\tvalid_1's l2: 4743.71\tvalid_1's RMSLE: 0.953708\n",
      "[180]\ttraining's l2: 4357.37\ttraining's RMSLE: 0.903996\tvalid_1's l2: 4412.04\tvalid_1's RMSLE: 0.92567\n",
      "[190]\ttraining's l2: 4073.86\ttraining's RMSLE: 0.877651\tvalid_1's l2: 4128.22\tvalid_1's RMSLE: 0.89894\n",
      "[200]\ttraining's l2: 3817.75\ttraining's RMSLE: 0.853367\tvalid_1's l2: 3877.03\tvalid_1's RMSLE: 0.874356\n",
      "[210]\ttraining's l2: 3589.21\ttraining's RMSLE: 0.830411\tvalid_1's l2: 3649.4\tvalid_1's RMSLE: 0.851107\n",
      "[220]\ttraining's l2: 3393.56\ttraining's RMSLE: 0.807489\tvalid_1's l2: 3458.2\tvalid_1's RMSLE: 0.827843\n",
      "[230]\ttraining's l2: 3216.53\ttraining's RMSLE: 0.786318\tvalid_1's l2: 3286.62\tvalid_1's RMSLE: 0.806377\n",
      "[240]\ttraining's l2: 3057.96\ttraining's RMSLE: 0.766669\tvalid_1's l2: 3132.17\tvalid_1's RMSLE: 0.786567\n",
      "[250]\ttraining's l2: 2909.92\ttraining's RMSLE: 0.747484\tvalid_1's l2: 2990\tvalid_1's RMSLE: 0.76712\n",
      "[260]\ttraining's l2: 2779.63\ttraining's RMSLE: 0.728928\tvalid_1's l2: 2866.19\tvalid_1's RMSLE: 0.748138\n",
      "[270]\ttraining's l2: 2657.59\ttraining's RMSLE: 0.713281\tvalid_1's l2: 2747.33\tvalid_1's RMSLE: 0.732007\n",
      "[280]\ttraining's l2: 2548.21\ttraining's RMSLE: 0.697882\tvalid_1's l2: 2639.25\tvalid_1's RMSLE: 0.716191\n",
      "[290]\ttraining's l2: 2452.17\ttraining's RMSLE: 0.683551\tvalid_1's l2: 2544.72\tvalid_1's RMSLE: 0.70159\n",
      "[300]\ttraining's l2: 2363.37\ttraining's RMSLE: 0.668793\tvalid_1's l2: 2453.89\tvalid_1's RMSLE: 0.686707\n",
      "[310]\ttraining's l2: 2286.15\ttraining's RMSLE: 0.655262\tvalid_1's l2: 2377.65\tvalid_1's RMSLE: 0.673112\n",
      "[320]\ttraining's l2: 2220.55\ttraining's RMSLE: 0.640259\tvalid_1's l2: 2313.01\tvalid_1's RMSLE: 0.657749\n",
      "[330]\ttraining's l2: 2158.71\ttraining's RMSLE: 0.626414\tvalid_1's l2: 2254.19\tvalid_1's RMSLE: 0.643902\n",
      "[340]\ttraining's l2: 2103.67\ttraining's RMSLE: 0.61263\tvalid_1's l2: 2204.47\tvalid_1's RMSLE: 0.630471\n",
      "[350]\ttraining's l2: 2049.64\ttraining's RMSLE: 0.599221\tvalid_1's l2: 2155.23\tvalid_1's RMSLE: 0.617301\n",
      "[360]\ttraining's l2: 1990.99\ttraining's RMSLE: 0.586548\tvalid_1's l2: 2102.71\tvalid_1's RMSLE: 0.605213\n",
      "[370]\ttraining's l2: 1947.95\ttraining's RMSLE: 0.574852\tvalid_1's l2: 2064.75\tvalid_1's RMSLE: 0.594275\n",
      "[380]\ttraining's l2: 1895.7\ttraining's RMSLE: 0.565828\tvalid_1's l2: 2018.42\tvalid_1's RMSLE: 0.58643\n",
      "[390]\ttraining's l2: 1849.34\ttraining's RMSLE: 0.555722\tvalid_1's l2: 1976.73\tvalid_1's RMSLE: 0.578068\n",
      "[400]\ttraining's l2: 1806.1\ttraining's RMSLE: 0.546066\tvalid_1's l2: 1939.5\tvalid_1's RMSLE: 0.568995\n",
      "[410]\ttraining's l2: 1760.39\ttraining's RMSLE: 0.53599\tvalid_1's l2: 1900.08\tvalid_1's RMSLE: 0.559885\n",
      "[420]\ttraining's l2: 1722.1\ttraining's RMSLE: 0.527308\tvalid_1's l2: 1866.66\tvalid_1's RMSLE: 0.551611\n",
      "[430]\ttraining's l2: 1683.43\ttraining's RMSLE: 0.517649\tvalid_1's l2: 1834.42\tvalid_1's RMSLE: 0.542387\n",
      "[440]\ttraining's l2: 1653.08\ttraining's RMSLE: 0.508822\tvalid_1's l2: 1808.82\tvalid_1's RMSLE: 0.533921\n",
      "[450]\ttraining's l2: 1621\ttraining's RMSLE: 0.500215\tvalid_1's l2: 1781.62\tvalid_1's RMSLE: 0.52619\n",
      "[460]\ttraining's l2: 1590.94\ttraining's RMSLE: 0.492635\tvalid_1's l2: 1757.86\tvalid_1's RMSLE: 0.519428\n",
      "[470]\ttraining's l2: 1562.34\ttraining's RMSLE: 0.486402\tvalid_1's l2: 1735.36\tvalid_1's RMSLE: 0.514085\n",
      "[480]\ttraining's l2: 1535.96\ttraining's RMSLE: 0.479291\tvalid_1's l2: 1714.65\tvalid_1's RMSLE: 0.508354\n",
      "[490]\ttraining's l2: 1513.09\ttraining's RMSLE: 0.474553\tvalid_1's l2: 1697.67\tvalid_1's RMSLE: 0.505382\n",
      "[500]\ttraining's l2: 1489.72\ttraining's RMSLE: 0.470395\tvalid_1's l2: 1680.17\tvalid_1's RMSLE: 0.501399\n",
      "[510]\ttraining's l2: 1466.87\ttraining's RMSLE: 0.464632\tvalid_1's l2: 1661.92\tvalid_1's RMSLE: 0.495782\n",
      "[520]\ttraining's l2: 1446.93\ttraining's RMSLE: 0.460582\tvalid_1's l2: 1647.73\tvalid_1's RMSLE: 0.492203\n",
      "[530]\ttraining's l2: 1426.74\ttraining's RMSLE: 0.455678\tvalid_1's l2: 1632.41\tvalid_1's RMSLE: 0.487962\n",
      "[540]\ttraining's l2: 1409.4\ttraining's RMSLE: 0.45216\tvalid_1's l2: 1619.89\tvalid_1's RMSLE: 0.485095\n",
      "[550]\ttraining's l2: 1393.36\ttraining's RMSLE: 0.448655\tvalid_1's l2: 1608.33\tvalid_1's RMSLE: 0.481527\n",
      "[560]\ttraining's l2: 1375.4\ttraining's RMSLE: 0.444984\tvalid_1's l2: 1594.8\tvalid_1's RMSLE: 0.478344\n",
      "[570]\ttraining's l2: 1359.51\ttraining's RMSLE: 0.442804\tvalid_1's l2: 1585.11\tvalid_1's RMSLE: 0.476835\n",
      "[580]\ttraining's l2: 1343.6\ttraining's RMSLE: 0.440413\tvalid_1's l2: 1574.65\tvalid_1's RMSLE: 0.475549\n",
      "[590]\ttraining's l2: 1329.46\ttraining's RMSLE: 0.438506\tvalid_1's l2: 1566.07\tvalid_1's RMSLE: 0.474496\n",
      "[600]\ttraining's l2: 1316.68\ttraining's RMSLE: 0.437224\tvalid_1's l2: 1557.65\tvalid_1's RMSLE: 0.474139\n",
      "[610]\ttraining's l2: 1303.98\ttraining's RMSLE: 0.435169\tvalid_1's l2: 1549.78\tvalid_1's RMSLE: 0.471831\n",
      "[620]\ttraining's l2: 1291.81\ttraining's RMSLE: 0.434164\tvalid_1's l2: 1542.47\tvalid_1's RMSLE: 0.471413\n",
      "[630]\ttraining's l2: 1279.49\ttraining's RMSLE: 0.433162\tvalid_1's l2: 1535.66\tvalid_1's RMSLE: 0.470598\n",
      "[640]\ttraining's l2: 1267.61\ttraining's RMSLE: 0.43256\tvalid_1's l2: 1528.88\tvalid_1's RMSLE: 0.469432\n",
      "[650]\ttraining's l2: 1256.19\ttraining's RMSLE: 0.430442\tvalid_1's l2: 1522\tvalid_1's RMSLE: 0.467209\n",
      "[660]\ttraining's l2: 1244.93\ttraining's RMSLE: 0.428189\tvalid_1's l2: 1514.93\tvalid_1's RMSLE: 0.464771\n",
      "[670]\ttraining's l2: 1233.65\ttraining's RMSLE: 0.426567\tvalid_1's l2: 1508.49\tvalid_1's RMSLE: 0.463212\n",
      "[680]\ttraining's l2: 1224.32\ttraining's RMSLE: 0.424987\tvalid_1's l2: 1501.97\tvalid_1's RMSLE: 0.461598\n",
      "[690]\ttraining's l2: 1214.9\ttraining's RMSLE: 0.423542\tvalid_1's l2: 1496.88\tvalid_1's RMSLE: 0.459939\n",
      "[700]\ttraining's l2: 1206.27\ttraining's RMSLE: 0.423204\tvalid_1's l2: 1492.72\tvalid_1's RMSLE: 0.459355\n",
      "[710]\ttraining's l2: 1196.89\ttraining's RMSLE: 0.421814\tvalid_1's l2: 1486.48\tvalid_1's RMSLE: 0.457535\n",
      "[720]\ttraining's l2: 1187.93\ttraining's RMSLE: 0.421117\tvalid_1's l2: 1480.83\tvalid_1's RMSLE: 0.456377\n",
      "[730]\ttraining's l2: 1177.36\ttraining's RMSLE: 0.418972\tvalid_1's l2: 1473\tvalid_1's RMSLE: 0.454502\n",
      "[740]\ttraining's l2: 1168.02\ttraining's RMSLE: 0.416731\tvalid_1's l2: 1466.55\tvalid_1's RMSLE: 0.451671\n",
      "[750]\ttraining's l2: 1158.76\ttraining's RMSLE: 0.414229\tvalid_1's l2: 1459.71\tvalid_1's RMSLE: 0.449731\n",
      "[760]\ttraining's l2: 1149.15\ttraining's RMSLE: 0.412462\tvalid_1's l2: 1453.69\tvalid_1's RMSLE: 0.448373\n",
      "[770]\ttraining's l2: 1139.47\ttraining's RMSLE: 0.410441\tvalid_1's l2: 1446.98\tvalid_1's RMSLE: 0.447892\n",
      "[780]\ttraining's l2: 1130.42\ttraining's RMSLE: 0.40867\tvalid_1's l2: 1442.19\tvalid_1's RMSLE: 0.44604\n",
      "[790]\ttraining's l2: 1122.08\ttraining's RMSLE: 0.407343\tvalid_1's l2: 1437.6\tvalid_1's RMSLE: 0.444652\n",
      "[800]\ttraining's l2: 1113.64\ttraining's RMSLE: 0.405515\tvalid_1's l2: 1432.66\tvalid_1's RMSLE: 0.442434\n",
      "[810]\ttraining's l2: 1105.95\ttraining's RMSLE: 0.404\tvalid_1's l2: 1427.99\tvalid_1's RMSLE: 0.439807\n",
      "[820]\ttraining's l2: 1099.3\ttraining's RMSLE: 0.403466\tvalid_1's l2: 1424.99\tvalid_1's RMSLE: 0.43888\n",
      "[830]\ttraining's l2: 1091.84\ttraining's RMSLE: 0.40208\tvalid_1's l2: 1419.47\tvalid_1's RMSLE: 0.436562\n",
      "[840]\ttraining's l2: 1084.66\ttraining's RMSLE: 0.400891\tvalid_1's l2: 1414.92\tvalid_1's RMSLE: 0.434747\n",
      "[850]\ttraining's l2: 1078.91\ttraining's RMSLE: 0.400154\tvalid_1's l2: 1411\tvalid_1's RMSLE: 0.433592\n",
      "[860]\ttraining's l2: 1072.5\ttraining's RMSLE: 0.399467\tvalid_1's l2: 1407.3\tvalid_1's RMSLE: 0.432335\n",
      "[870]\ttraining's l2: 1066.79\ttraining's RMSLE: 0.398872\tvalid_1's l2: 1402.88\tvalid_1's RMSLE: 0.431578\n",
      "[880]\ttraining's l2: 1060.29\ttraining's RMSLE: 0.39829\tvalid_1's l2: 1398.48\tvalid_1's RMSLE: 0.43108\n",
      "[890]\ttraining's l2: 1054.56\ttraining's RMSLE: 0.397143\tvalid_1's l2: 1394.34\tvalid_1's RMSLE: 0.429805\n",
      "[900]\ttraining's l2: 1048.5\ttraining's RMSLE: 0.396583\tvalid_1's l2: 1391.07\tvalid_1's RMSLE: 0.429209\n",
      "[910]\ttraining's l2: 1042.98\ttraining's RMSLE: 0.395963\tvalid_1's l2: 1386.98\tvalid_1's RMSLE: 0.428705\n",
      "[920]\ttraining's l2: 1037.08\ttraining's RMSLE: 0.395423\tvalid_1's l2: 1382.55\tvalid_1's RMSLE: 0.427919\n",
      "[930]\ttraining's l2: 1032\ttraining's RMSLE: 0.394453\tvalid_1's l2: 1379.14\tvalid_1's RMSLE: 0.42696\n",
      "[940]\ttraining's l2: 1026.48\ttraining's RMSLE: 0.393947\tvalid_1's l2: 1375.86\tvalid_1's RMSLE: 0.426527\n",
      "[950]\ttraining's l2: 1021.51\ttraining's RMSLE: 0.393687\tvalid_1's l2: 1373.8\tvalid_1's RMSLE: 0.426915\n",
      "Early stopping, best iteration is:\n",
      "[940]\ttraining's l2: 1026.48\ttraining's RMSLE: 0.393947\tvalid_1's l2: 1375.86\tvalid_1's RMSLE: 0.426527\n",
      "predict valid for fold 0\n",
      "save model for fold 0\n",
      "start training for fold 1\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 296\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 192.251120\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 28350.1\ttraining's RMSLE: 1.52065\tvalid_1's l2: 27201\tvalid_1's RMSLE: 1.50236\n",
      "[20]\ttraining's l2: 24347.2\ttraining's RMSLE: 1.4715\tvalid_1's l2: 23409.6\tvalid_1's RMSLE: 1.45442\n",
      "[30]\ttraining's l2: 21054.8\ttraining's RMSLE: 1.42574\tvalid_1's l2: 20309.3\tvalid_1's RMSLE: 1.41001\n",
      "[40]\ttraining's l2: 18309.1\ttraining's RMSLE: 1.38236\tvalid_1's l2: 17727\tvalid_1's RMSLE: 1.36804\n",
      "[50]\ttraining's l2: 16033.4\ttraining's RMSLE: 1.34129\tvalid_1's l2: 15596.1\tvalid_1's RMSLE: 1.3283\n",
      "[60]\ttraining's l2: 14127.8\ttraining's RMSLE: 1.30235\tvalid_1's l2: 13810.8\tvalid_1's RMSLE: 1.29069\n",
      "[70]\ttraining's l2: 12529.7\ttraining's RMSLE: 1.26489\tvalid_1's l2: 12311.2\tvalid_1's RMSLE: 1.25434\n",
      "[80]\ttraining's l2: 11181.8\ttraining's RMSLE: 1.22882\tvalid_1's l2: 11044.4\tvalid_1's RMSLE: 1.21943\n",
      "[90]\ttraining's l2: 10032.7\ttraining's RMSLE: 1.19366\tvalid_1's l2: 9971.54\tvalid_1's RMSLE: 1.1854\n",
      "[100]\ttraining's l2: 9043.23\ttraining's RMSLE: 1.16013\tvalid_1's l2: 9047.61\tvalid_1's RMSLE: 1.15293\n",
      "[110]\ttraining's l2: 8172.91\ttraining's RMSLE: 1.12802\tvalid_1's l2: 8216.88\tvalid_1's RMSLE: 1.12151\n",
      "[120]\ttraining's l2: 7352.75\ttraining's RMSLE: 1.09449\tvalid_1's l2: 7424.78\tvalid_1's RMSLE: 1.0888\n",
      "[130]\ttraining's l2: 6632.19\ttraining's RMSLE: 1.06114\tvalid_1's l2: 6723.95\tvalid_1's RMSLE: 1.0562\n",
      "[140]\ttraining's l2: 6026.5\ttraining's RMSLE: 1.02914\tvalid_1's l2: 6134.89\tvalid_1's RMSLE: 1.02492\n",
      "[150]\ttraining's l2: 5506.25\ttraining's RMSLE: 0.998534\tvalid_1's l2: 5635.59\tvalid_1's RMSLE: 0.995087\n",
      "[160]\ttraining's l2: 5057.42\ttraining's RMSLE: 0.9685\tvalid_1's l2: 5199.04\tvalid_1's RMSLE: 0.965739\n",
      "[170]\ttraining's l2: 4668.89\ttraining's RMSLE: 0.939411\tvalid_1's l2: 4820.35\tvalid_1's RMSLE: 0.937235\n",
      "[180]\ttraining's l2: 4307.44\ttraining's RMSLE: 0.912355\tvalid_1's l2: 4472.72\tvalid_1's RMSLE: 0.910819\n",
      "[190]\ttraining's l2: 3995.36\ttraining's RMSLE: 0.885134\tvalid_1's l2: 4177.98\tvalid_1's RMSLE: 0.88433\n",
      "[200]\ttraining's l2: 3730.45\ttraining's RMSLE: 0.861032\tvalid_1's l2: 3927.02\tvalid_1's RMSLE: 0.860783\n",
      "[210]\ttraining's l2: 3499.75\ttraining's RMSLE: 0.836883\tvalid_1's l2: 3709.56\tvalid_1's RMSLE: 0.837164\n",
      "[220]\ttraining's l2: 3285.66\ttraining's RMSLE: 0.815218\tvalid_1's l2: 3508.53\tvalid_1's RMSLE: 0.815993\n",
      "[230]\ttraining's l2: 3098.04\ttraining's RMSLE: 0.794135\tvalid_1's l2: 3326.39\tvalid_1's RMSLE: 0.795276\n",
      "[240]\ttraining's l2: 2935.2\ttraining's RMSLE: 0.773782\tvalid_1's l2: 3167.15\tvalid_1's RMSLE: 0.775292\n",
      "[250]\ttraining's l2: 2789.75\ttraining's RMSLE: 0.753854\tvalid_1's l2: 3027.24\tvalid_1's RMSLE: 0.755716\n",
      "[260]\ttraining's l2: 2666.8\ttraining's RMSLE: 0.735302\tvalid_1's l2: 2914.16\tvalid_1's RMSLE: 0.73794\n",
      "[270]\ttraining's l2: 2564.05\ttraining's RMSLE: 0.718935\tvalid_1's l2: 2820.53\tvalid_1's RMSLE: 0.722162\n",
      "[280]\ttraining's l2: 2470.97\ttraining's RMSLE: 0.703247\tvalid_1's l2: 2737\tvalid_1's RMSLE: 0.706975\n",
      "[290]\ttraining's l2: 2383.61\ttraining's RMSLE: 0.687345\tvalid_1's l2: 2656.64\tvalid_1's RMSLE: 0.691461\n",
      "[300]\ttraining's l2: 2301.64\ttraining's RMSLE: 0.672335\tvalid_1's l2: 2580.11\tvalid_1's RMSLE: 0.676657\n",
      "[310]\ttraining's l2: 2230.89\ttraining's RMSLE: 0.658144\tvalid_1's l2: 2517.19\tvalid_1's RMSLE: 0.662743\n",
      "[320]\ttraining's l2: 2169.78\ttraining's RMSLE: 0.644865\tvalid_1's l2: 2463.83\tvalid_1's RMSLE: 0.649768\n",
      "[330]\ttraining's l2: 2106.78\ttraining's RMSLE: 0.631444\tvalid_1's l2: 2405.41\tvalid_1's RMSLE: 0.636328\n",
      "[340]\ttraining's l2: 2049.7\ttraining's RMSLE: 0.618504\tvalid_1's l2: 2354.53\tvalid_1's RMSLE: 0.623686\n",
      "[350]\ttraining's l2: 1997.85\ttraining's RMSLE: 0.606965\tvalid_1's l2: 2309.93\tvalid_1's RMSLE: 0.612161\n",
      "[360]\ttraining's l2: 1944.16\ttraining's RMSLE: 0.595225\tvalid_1's l2: 2261.36\tvalid_1's RMSLE: 0.600425\n",
      "[370]\ttraining's l2: 1892.63\ttraining's RMSLE: 0.584036\tvalid_1's l2: 2215.13\tvalid_1's RMSLE: 0.589186\n",
      "[380]\ttraining's l2: 1848.77\ttraining's RMSLE: 0.572559\tvalid_1's l2: 2175.92\tvalid_1's RMSLE: 0.577793\n",
      "[390]\ttraining's l2: 1801.61\ttraining's RMSLE: 0.563045\tvalid_1's l2: 2136.6\tvalid_1's RMSLE: 0.568497\n",
      "[400]\ttraining's l2: 1762.61\ttraining's RMSLE: 0.552527\tvalid_1's l2: 2102.41\tvalid_1's RMSLE: 0.558415\n",
      "[410]\ttraining's l2: 1723.05\ttraining's RMSLE: 0.543961\tvalid_1's l2: 2068.41\tvalid_1's RMSLE: 0.550249\n",
      "[420]\ttraining's l2: 1684.66\ttraining's RMSLE: 0.535922\tvalid_1's l2: 2035.25\tvalid_1's RMSLE: 0.542312\n",
      "[430]\ttraining's l2: 1650.65\ttraining's RMSLE: 0.528072\tvalid_1's l2: 2003.98\tvalid_1's RMSLE: 0.534481\n",
      "[440]\ttraining's l2: 1618.35\ttraining's RMSLE: 0.520813\tvalid_1's l2: 1976.1\tvalid_1's RMSLE: 0.52703\n",
      "[450]\ttraining's l2: 1587.56\ttraining's RMSLE: 0.514428\tvalid_1's l2: 1949.41\tvalid_1's RMSLE: 0.520428\n",
      "[460]\ttraining's l2: 1561.42\ttraining's RMSLE: 0.507708\tvalid_1's l2: 1926.8\tvalid_1's RMSLE: 0.513671\n",
      "[470]\ttraining's l2: 1535.69\ttraining's RMSLE: 0.501496\tvalid_1's l2: 1906.67\tvalid_1's RMSLE: 0.508246\n",
      "[480]\ttraining's l2: 1512.67\ttraining's RMSLE: 0.49647\tvalid_1's l2: 1887.31\tvalid_1's RMSLE: 0.504061\n",
      "[490]\ttraining's l2: 1489.69\ttraining's RMSLE: 0.491735\tvalid_1's l2: 1868.3\tvalid_1's RMSLE: 0.500633\n",
      "[500]\ttraining's l2: 1467.9\ttraining's RMSLE: 0.486648\tvalid_1's l2: 1850.93\tvalid_1's RMSLE: 0.4975\n",
      "[510]\ttraining's l2: 1447.34\ttraining's RMSLE: 0.481716\tvalid_1's l2: 1834.09\tvalid_1's RMSLE: 0.496255\n",
      "[520]\ttraining's l2: 1427.73\ttraining's RMSLE: 0.477273\tvalid_1's l2: 1816.46\tvalid_1's RMSLE: 0.493647\n",
      "[530]\ttraining's l2: 1410.62\ttraining's RMSLE: 0.473991\tvalid_1's l2: 1802.04\tvalid_1's RMSLE: 0.490788\n",
      "[540]\ttraining's l2: 1392.28\ttraining's RMSLE: 0.469738\tvalid_1's l2: 1788.06\tvalid_1's RMSLE: 0.486887\n",
      "[550]\ttraining's l2: 1374.08\ttraining's RMSLE: 0.465723\tvalid_1's l2: 1772.52\tvalid_1's RMSLE: 0.483808\n",
      "[560]\ttraining's l2: 1357.72\ttraining's RMSLE: 0.462256\tvalid_1's l2: 1759.09\tvalid_1's RMSLE: 0.480279\n",
      "[570]\ttraining's l2: 1341.72\ttraining's RMSLE: 0.458473\tvalid_1's l2: 1747.27\tvalid_1's RMSLE: 0.475643\n",
      "[580]\ttraining's l2: 1327.84\ttraining's RMSLE: 0.456402\tvalid_1's l2: 1736.81\tvalid_1's RMSLE: 0.473069\n",
      "[590]\ttraining's l2: 1315.01\ttraining's RMSLE: 0.454242\tvalid_1's l2: 1727.7\tvalid_1's RMSLE: 0.470574\n",
      "[600]\ttraining's l2: 1303.24\ttraining's RMSLE: 0.452526\tvalid_1's l2: 1719.59\tvalid_1's RMSLE: 0.469039\n",
      "[610]\ttraining's l2: 1291.41\ttraining's RMSLE: 0.451006\tvalid_1's l2: 1711.44\tvalid_1's RMSLE: 0.46761\n",
      "[620]\ttraining's l2: 1280.18\ttraining's RMSLE: 0.449075\tvalid_1's l2: 1703.53\tvalid_1's RMSLE: 0.465789\n",
      "[630]\ttraining's l2: 1269.33\ttraining's RMSLE: 0.44786\tvalid_1's l2: 1695.4\tvalid_1's RMSLE: 0.464168\n",
      "[640]\ttraining's l2: 1257.46\ttraining's RMSLE: 0.445708\tvalid_1's l2: 1686.49\tvalid_1's RMSLE: 0.461852\n",
      "[650]\ttraining's l2: 1244.96\ttraining's RMSLE: 0.443553\tvalid_1's l2: 1676.51\tvalid_1's RMSLE: 0.459617\n",
      "[660]\ttraining's l2: 1233.9\ttraining's RMSLE: 0.441686\tvalid_1's l2: 1667.43\tvalid_1's RMSLE: 0.457628\n",
      "[670]\ttraining's l2: 1223.66\ttraining's RMSLE: 0.439884\tvalid_1's l2: 1660.83\tvalid_1's RMSLE: 0.456775\n",
      "[680]\ttraining's l2: 1213.91\ttraining's RMSLE: 0.439009\tvalid_1's l2: 1656.41\tvalid_1's RMSLE: 0.456126\n",
      "[690]\ttraining's l2: 1203.7\ttraining's RMSLE: 0.43603\tvalid_1's l2: 1649.28\tvalid_1's RMSLE: 0.454585\n",
      "[700]\ttraining's l2: 1194.49\ttraining's RMSLE: 0.43399\tvalid_1's l2: 1641.87\tvalid_1's RMSLE: 0.453191\n",
      "[710]\ttraining's l2: 1185.33\ttraining's RMSLE: 0.432995\tvalid_1's l2: 1635.35\tvalid_1's RMSLE: 0.451582\n",
      "[720]\ttraining's l2: 1176.7\ttraining's RMSLE: 0.431415\tvalid_1's l2: 1628.95\tvalid_1's RMSLE: 0.450676\n",
      "[730]\ttraining's l2: 1167.98\ttraining's RMSLE: 0.429776\tvalid_1's l2: 1622.47\tvalid_1's RMSLE: 0.449168\n",
      "[740]\ttraining's l2: 1158.44\ttraining's RMSLE: 0.427179\tvalid_1's l2: 1614.93\tvalid_1's RMSLE: 0.446927\n",
      "[750]\ttraining's l2: 1149.37\ttraining's RMSLE: 0.425345\tvalid_1's l2: 1609.71\tvalid_1's RMSLE: 0.445249\n",
      "[760]\ttraining's l2: 1140.36\ttraining's RMSLE: 0.423463\tvalid_1's l2: 1604.46\tvalid_1's RMSLE: 0.443484\n",
      "[770]\ttraining's l2: 1132\ttraining's RMSLE: 0.421145\tvalid_1's l2: 1598.85\tvalid_1's RMSLE: 0.441355\n",
      "[780]\ttraining's l2: 1124.19\ttraining's RMSLE: 0.419802\tvalid_1's l2: 1593.34\tvalid_1's RMSLE: 0.43986\n",
      "[790]\ttraining's l2: 1116.73\ttraining's RMSLE: 0.417793\tvalid_1's l2: 1588.27\tvalid_1's RMSLE: 0.43776\n",
      "[800]\ttraining's l2: 1109.11\ttraining's RMSLE: 0.415887\tvalid_1's l2: 1583.03\tvalid_1's RMSLE: 0.436127\n",
      "[810]\ttraining's l2: 1101.83\ttraining's RMSLE: 0.413324\tvalid_1's l2: 1578.81\tvalid_1's RMSLE: 0.433797\n",
      "[820]\ttraining's l2: 1095.25\ttraining's RMSLE: 0.411744\tvalid_1's l2: 1574.3\tvalid_1's RMSLE: 0.432227\n",
      "[830]\ttraining's l2: 1088.32\ttraining's RMSLE: 0.40988\tvalid_1's l2: 1570.12\tvalid_1's RMSLE: 0.430668\n",
      "[840]\ttraining's l2: 1081.04\ttraining's RMSLE: 0.407862\tvalid_1's l2: 1564.73\tvalid_1's RMSLE: 0.429289\n",
      "[850]\ttraining's l2: 1074.62\ttraining's RMSLE: 0.4069\tvalid_1's l2: 1560.57\tvalid_1's RMSLE: 0.428542\n",
      "[860]\ttraining's l2: 1068.1\ttraining's RMSLE: 0.405484\tvalid_1's l2: 1557.1\tvalid_1's RMSLE: 0.427522\n",
      "[870]\ttraining's l2: 1061.81\ttraining's RMSLE: 0.403702\tvalid_1's l2: 1552.82\tvalid_1's RMSLE: 0.425408\n",
      "[880]\ttraining's l2: 1056.02\ttraining's RMSLE: 0.402528\tvalid_1's l2: 1548.58\tvalid_1's RMSLE: 0.424377\n",
      "[890]\ttraining's l2: 1050.9\ttraining's RMSLE: 0.401414\tvalid_1's l2: 1545.67\tvalid_1's RMSLE: 0.423258\n",
      "[900]\ttraining's l2: 1046.37\ttraining's RMSLE: 0.400723\tvalid_1's l2: 1542.73\tvalid_1's RMSLE: 0.422735\n",
      "[910]\ttraining's l2: 1041.25\ttraining's RMSLE: 0.400177\tvalid_1's l2: 1539.24\tvalid_1's RMSLE: 0.422306\n",
      "[920]\ttraining's l2: 1036.52\ttraining's RMSLE: 0.399631\tvalid_1's l2: 1536.04\tvalid_1's RMSLE: 0.421981\n",
      "[930]\ttraining's l2: 1031.31\ttraining's RMSLE: 0.399011\tvalid_1's l2: 1533.34\tvalid_1's RMSLE: 0.42161\n",
      "[940]\ttraining's l2: 1026.5\ttraining's RMSLE: 0.398039\tvalid_1's l2: 1530.55\tvalid_1's RMSLE: 0.420412\n",
      "[950]\ttraining's l2: 1021.14\ttraining's RMSLE: 0.39705\tvalid_1's l2: 1526.7\tvalid_1's RMSLE: 0.4195\n",
      "[960]\ttraining's l2: 1016.21\ttraining's RMSLE: 0.396577\tvalid_1's l2: 1523.94\tvalid_1's RMSLE: 0.41905\n",
      "[970]\ttraining's l2: 1011.9\ttraining's RMSLE: 0.39571\tvalid_1's l2: 1521.39\tvalid_1's RMSLE: 0.418335\n",
      "[980]\ttraining's l2: 1007.28\ttraining's RMSLE: 0.394549\tvalid_1's l2: 1518.89\tvalid_1's RMSLE: 0.417918\n",
      "[990]\ttraining's l2: 1002.54\ttraining's RMSLE: 0.39374\tvalid_1's l2: 1515.75\tvalid_1's RMSLE: 0.417396\n",
      "[1000]\ttraining's l2: 997.681\ttraining's RMSLE: 0.393201\tvalid_1's l2: 1512.47\tvalid_1's RMSLE: 0.416907\n",
      "[1010]\ttraining's l2: 993.548\ttraining's RMSLE: 0.392496\tvalid_1's l2: 1510.43\tvalid_1's RMSLE: 0.416805\n",
      "Early stopping, best iteration is:\n",
      "[1008]\ttraining's l2: 994.356\ttraining's RMSLE: 0.392501\tvalid_1's l2: 1510.46\tvalid_1's RMSLE: 0.416589\n",
      "predict valid for fold 1\n",
      "save model for fold 1\n",
      "start training for fold 2\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 296\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 192.640717\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 27988.5\ttraining's RMSLE: 1.51184\tvalid_1's l2: 28458.5\tvalid_1's RMSLE: 1.54233\n",
      "[20]\ttraining's l2: 24148.2\ttraining's RMSLE: 1.46347\tvalid_1's l2: 24559.8\tvalid_1's RMSLE: 1.49295\n",
      "[30]\ttraining's l2: 20959\ttraining's RMSLE: 1.41851\tvalid_1's l2: 21343.3\tvalid_1's RMSLE: 1.44707\n",
      "[40]\ttraining's l2: 18244.6\ttraining's RMSLE: 1.37597\tvalid_1's l2: 18595.9\tvalid_1's RMSLE: 1.40361\n",
      "[50]\ttraining's l2: 15963.1\ttraining's RMSLE: 1.33563\tvalid_1's l2: 16284.4\tvalid_1's RMSLE: 1.36226\n",
      "[60]\ttraining's l2: 14049.6\ttraining's RMSLE: 1.29712\tvalid_1's l2: 14356.5\tvalid_1's RMSLE: 1.32274\n",
      "[70]\ttraining's l2: 12446.6\ttraining's RMSLE: 1.2602\tvalid_1's l2: 12734.5\tvalid_1's RMSLE: 1.28481\n",
      "[80]\ttraining's l2: 11105.8\ttraining's RMSLE: 1.22436\tvalid_1's l2: 11384.2\tvalid_1's RMSLE: 1.24795\n",
      "[90]\ttraining's l2: 9968.18\ttraining's RMSLE: 1.1895\tvalid_1's l2: 10245.9\tvalid_1's RMSLE: 1.21215\n",
      "[100]\ttraining's l2: 8935.57\ttraining's RMSLE: 1.15435\tvalid_1's l2: 9202.25\tvalid_1's RMSLE: 1.17608\n",
      "[110]\ttraining's l2: 8003.71\ttraining's RMSLE: 1.12027\tvalid_1's l2: 8259.25\tvalid_1's RMSLE: 1.14111\n",
      "[120]\ttraining's l2: 7194.09\ttraining's RMSLE: 1.08659\tvalid_1's l2: 7450.08\tvalid_1's RMSLE: 1.10661\n",
      "[130]\ttraining's l2: 6500.25\ttraining's RMSLE: 1.05297\tvalid_1's l2: 6753.82\tvalid_1's RMSLE: 1.07219\n",
      "[140]\ttraining's l2: 5917.62\ttraining's RMSLE: 1.02051\tvalid_1's l2: 6167.15\tvalid_1's RMSLE: 1.03895\n",
      "[150]\ttraining's l2: 5422.32\ttraining's RMSLE: 0.989129\tvalid_1's l2: 5671.3\tvalid_1's RMSLE: 1.00681\n",
      "[160]\ttraining's l2: 5000.84\ttraining's RMSLE: 0.95943\tvalid_1's l2: 5256.3\tvalid_1's RMSLE: 0.976505\n",
      "[170]\ttraining's l2: 4635.05\ttraining's RMSLE: 0.930124\tvalid_1's l2: 4893.23\tvalid_1's RMSLE: 0.946544\n",
      "[180]\ttraining's l2: 4316.45\ttraining's RMSLE: 0.90308\tvalid_1's l2: 4580.12\tvalid_1's RMSLE: 0.919019\n",
      "[190]\ttraining's l2: 4028.9\ttraining's RMSLE: 0.876464\tvalid_1's l2: 4303.85\tvalid_1's RMSLE: 0.89202\n",
      "[200]\ttraining's l2: 3767.49\ttraining's RMSLE: 0.851318\tvalid_1's l2: 4048.69\tvalid_1's RMSLE: 0.866516\n",
      "[210]\ttraining's l2: 3535.3\ttraining's RMSLE: 0.828378\tvalid_1's l2: 3824.04\tvalid_1's RMSLE: 0.84332\n",
      "[220]\ttraining's l2: 3328.05\ttraining's RMSLE: 0.806875\tvalid_1's l2: 3625.68\tvalid_1's RMSLE: 0.821696\n",
      "[230]\ttraining's l2: 3141.04\ttraining's RMSLE: 0.785684\tvalid_1's l2: 3448.77\tvalid_1's RMSLE: 0.800357\n",
      "[240]\ttraining's l2: 2965.02\ttraining's RMSLE: 0.765969\tvalid_1's l2: 3282.62\tvalid_1's RMSLE: 0.780641\n",
      "[250]\ttraining's l2: 2820.67\ttraining's RMSLE: 0.746918\tvalid_1's l2: 3148.87\tvalid_1's RMSLE: 0.761713\n",
      "[260]\ttraining's l2: 2689.13\ttraining's RMSLE: 0.73032\tvalid_1's l2: 3022.68\tvalid_1's RMSLE: 0.744835\n",
      "[270]\ttraining's l2: 2569.24\ttraining's RMSLE: 0.713512\tvalid_1's l2: 2905.88\tvalid_1's RMSLE: 0.727795\n",
      "[280]\ttraining's l2: 2469.76\ttraining's RMSLE: 0.69713\tvalid_1's l2: 2812.18\tvalid_1's RMSLE: 0.711374\n",
      "[290]\ttraining's l2: 2379.02\ttraining's RMSLE: 0.681905\tvalid_1's l2: 2724.8\tvalid_1's RMSLE: 0.696083\n",
      "[300]\ttraining's l2: 2292.89\ttraining's RMSLE: 0.66649\tvalid_1's l2: 2645.17\tvalid_1's RMSLE: 0.680528\n",
      "[310]\ttraining's l2: 2216.38\ttraining's RMSLE: 0.651927\tvalid_1's l2: 2573.91\tvalid_1's RMSLE: 0.665772\n",
      "[320]\ttraining's l2: 2145.77\ttraining's RMSLE: 0.638841\tvalid_1's l2: 2506.61\tvalid_1's RMSLE: 0.652722\n",
      "[330]\ttraining's l2: 2077.27\ttraining's RMSLE: 0.62607\tvalid_1's l2: 2443.46\tvalid_1's RMSLE: 0.640098\n",
      "[340]\ttraining's l2: 2013.46\ttraining's RMSLE: 0.612811\tvalid_1's l2: 2384.71\tvalid_1's RMSLE: 0.626775\n",
      "[350]\ttraining's l2: 1959.15\ttraining's RMSLE: 0.59957\tvalid_1's l2: 2335.8\tvalid_1's RMSLE: 0.613349\n",
      "[360]\ttraining's l2: 1908.37\ttraining's RMSLE: 0.587307\tvalid_1's l2: 2290.22\tvalid_1's RMSLE: 0.600919\n",
      "[370]\ttraining's l2: 1860.23\ttraining's RMSLE: 0.575197\tvalid_1's l2: 2245.92\tvalid_1's RMSLE: 0.588535\n",
      "[380]\ttraining's l2: 1817.96\ttraining's RMSLE: 0.563505\tvalid_1's l2: 2209.5\tvalid_1's RMSLE: 0.576752\n",
      "[390]\ttraining's l2: 1777.23\ttraining's RMSLE: 0.553397\tvalid_1's l2: 2173.42\tvalid_1's RMSLE: 0.566369\n",
      "[400]\ttraining's l2: 1733.42\ttraining's RMSLE: 0.544396\tvalid_1's l2: 2135.51\tvalid_1's RMSLE: 0.556552\n",
      "[410]\ttraining's l2: 1693.03\ttraining's RMSLE: 0.535454\tvalid_1's l2: 2099.22\tvalid_1's RMSLE: 0.547204\n",
      "[420]\ttraining's l2: 1655.22\ttraining's RMSLE: 0.527683\tvalid_1's l2: 2065.67\tvalid_1's RMSLE: 0.539584\n",
      "[430]\ttraining's l2: 1620.93\ttraining's RMSLE: 0.520574\tvalid_1's l2: 2034.32\tvalid_1's RMSLE: 0.532377\n",
      "[440]\ttraining's l2: 1588.7\ttraining's RMSLE: 0.513829\tvalid_1's l2: 2005.06\tvalid_1's RMSLE: 0.525861\n",
      "[450]\ttraining's l2: 1558.56\ttraining's RMSLE: 0.508063\tvalid_1's l2: 1978.88\tvalid_1's RMSLE: 0.51944\n",
      "[460]\ttraining's l2: 1531.14\ttraining's RMSLE: 0.502804\tvalid_1's l2: 1955.29\tvalid_1's RMSLE: 0.51391\n",
      "[470]\ttraining's l2: 1504.74\ttraining's RMSLE: 0.497215\tvalid_1's l2: 1931.89\tvalid_1's RMSLE: 0.50796\n",
      "[480]\ttraining's l2: 1479.29\ttraining's RMSLE: 0.491281\tvalid_1's l2: 1909.52\tvalid_1's RMSLE: 0.501659\n",
      "[490]\ttraining's l2: 1454.96\ttraining's RMSLE: 0.48664\tvalid_1's l2: 1889.17\tvalid_1's RMSLE: 0.496831\n",
      "[500]\ttraining's l2: 1432.51\ttraining's RMSLE: 0.480986\tvalid_1's l2: 1869.16\tvalid_1's RMSLE: 0.491869\n",
      "[510]\ttraining's l2: 1410.26\ttraining's RMSLE: 0.476566\tvalid_1's l2: 1849.58\tvalid_1's RMSLE: 0.486985\n",
      "[520]\ttraining's l2: 1390.34\ttraining's RMSLE: 0.473069\tvalid_1's l2: 1831.59\tvalid_1's RMSLE: 0.483165\n",
      "[530]\ttraining's l2: 1370.43\ttraining's RMSLE: 0.466895\tvalid_1's l2: 1813.45\tvalid_1's RMSLE: 0.476487\n",
      "[540]\ttraining's l2: 1351.39\ttraining's RMSLE: 0.461802\tvalid_1's l2: 1797.76\tvalid_1's RMSLE: 0.472374\n",
      "[550]\ttraining's l2: 1332.8\ttraining's RMSLE: 0.456845\tvalid_1's l2: 1781.53\tvalid_1's RMSLE: 0.46757\n",
      "[560]\ttraining's l2: 1317.25\ttraining's RMSLE: 0.452393\tvalid_1's l2: 1768.57\tvalid_1's RMSLE: 0.462943\n",
      "[570]\ttraining's l2: 1301.85\ttraining's RMSLE: 0.449034\tvalid_1's l2: 1755.42\tvalid_1's RMSLE: 0.459349\n",
      "[580]\ttraining's l2: 1287.8\ttraining's RMSLE: 0.445398\tvalid_1's l2: 1743.42\tvalid_1's RMSLE: 0.45565\n",
      "[590]\ttraining's l2: 1273.89\ttraining's RMSLE: 0.442241\tvalid_1's l2: 1731.59\tvalid_1's RMSLE: 0.452456\n",
      "[600]\ttraining's l2: 1261.08\ttraining's RMSLE: 0.439272\tvalid_1's l2: 1720.98\tvalid_1's RMSLE: 0.449241\n",
      "[610]\ttraining's l2: 1248.85\ttraining's RMSLE: 0.436618\tvalid_1's l2: 1710.77\tvalid_1's RMSLE: 0.445992\n",
      "[620]\ttraining's l2: 1237.04\ttraining's RMSLE: 0.433416\tvalid_1's l2: 1701.15\tvalid_1's RMSLE: 0.442284\n",
      "[630]\ttraining's l2: 1224.91\ttraining's RMSLE: 0.43158\tvalid_1's l2: 1691.92\tvalid_1's RMSLE: 0.4398\n",
      "[640]\ttraining's l2: 1213.75\ttraining's RMSLE: 0.429624\tvalid_1's l2: 1683.21\tvalid_1's RMSLE: 0.438201\n",
      "[650]\ttraining's l2: 1202.07\ttraining's RMSLE: 0.427489\tvalid_1's l2: 1675.47\tvalid_1's RMSLE: 0.436413\n",
      "[660]\ttraining's l2: 1190.96\ttraining's RMSLE: 0.425738\tvalid_1's l2: 1667.4\tvalid_1's RMSLE: 0.435041\n",
      "[670]\ttraining's l2: 1180.77\ttraining's RMSLE: 0.424206\tvalid_1's l2: 1659.76\tvalid_1's RMSLE: 0.434171\n",
      "[680]\ttraining's l2: 1170.36\ttraining's RMSLE: 0.423062\tvalid_1's l2: 1652.91\tvalid_1's RMSLE: 0.433243\n",
      "[690]\ttraining's l2: 1160.07\ttraining's RMSLE: 0.422044\tvalid_1's l2: 1645.85\tvalid_1's RMSLE: 0.432668\n",
      "[700]\ttraining's l2: 1149.57\ttraining's RMSLE: 0.419041\tvalid_1's l2: 1636.32\tvalid_1's RMSLE: 0.430346\n",
      "[710]\ttraining's l2: 1138.91\ttraining's RMSLE: 0.416603\tvalid_1's l2: 1627.72\tvalid_1's RMSLE: 0.428864\n",
      "[720]\ttraining's l2: 1129.48\ttraining's RMSLE: 0.414875\tvalid_1's l2: 1620.41\tvalid_1's RMSLE: 0.428391\n",
      "Early stopping, best iteration is:\n",
      "[718]\ttraining's l2: 1131.25\ttraining's RMSLE: 0.415052\tvalid_1's l2: 1621.5\tvalid_1's RMSLE: 0.428351\n",
      "predict valid for fold 2\n",
      "save model for fold 2\n",
      "start training for fold 3\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 296\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 189.636927\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 27795.3\ttraining's RMSLE: 1.52658\tvalid_1's l2: 29005.8\tvalid_1's RMSLE: 1.44515\n",
      "[20]\ttraining's l2: 23923.5\ttraining's RMSLE: 1.47745\tvalid_1's l2: 25061.7\tvalid_1's RMSLE: 1.39702\n",
      "[30]\ttraining's l2: 20693.2\ttraining's RMSLE: 1.43169\tvalid_1's l2: 21771.1\tvalid_1's RMSLE: 1.35248\n",
      "[40]\ttraining's l2: 18006.9\ttraining's RMSLE: 1.38859\tvalid_1's l2: 19042.5\tvalid_1's RMSLE: 1.31081\n",
      "[50]\ttraining's l2: 15806.1\ttraining's RMSLE: 1.34789\tvalid_1's l2: 16784.6\tvalid_1's RMSLE: 1.27151\n",
      "[60]\ttraining's l2: 13956.9\ttraining's RMSLE: 1.30916\tvalid_1's l2: 14882.5\tvalid_1's RMSLE: 1.23429\n",
      "[70]\ttraining's l2: 12396.4\ttraining's RMSLE: 1.27197\tvalid_1's l2: 13295.2\tvalid_1's RMSLE: 1.19882\n",
      "[80]\ttraining's l2: 11090.3\ttraining's RMSLE: 1.23599\tvalid_1's l2: 11967.7\tvalid_1's RMSLE: 1.16466\n",
      "[90]\ttraining's l2: 9994.24\ttraining's RMSLE: 1.2014\tvalid_1's l2: 10853.8\tvalid_1's RMSLE: 1.13191\n",
      "[100]\ttraining's l2: 9045.73\ttraining's RMSLE: 1.1688\tvalid_1's l2: 9894.05\tvalid_1's RMSLE: 1.10096\n",
      "[110]\ttraining's l2: 8136.07\ttraining's RMSLE: 1.13545\tvalid_1's l2: 8956.41\tvalid_1's RMSLE: 1.06931\n",
      "[120]\ttraining's l2: 7297.76\ttraining's RMSLE: 1.10026\tvalid_1's l2: 8074.88\tvalid_1's RMSLE: 1.03601\n",
      "[130]\ttraining's l2: 6596.39\ttraining's RMSLE: 1.06714\tvalid_1's l2: 7352.15\tvalid_1's RMSLE: 1.00489\n",
      "[140]\ttraining's l2: 6006.1\ttraining's RMSLE: 1.03534\tvalid_1's l2: 6736.23\tvalid_1's RMSLE: 0.97512\n",
      "[150]\ttraining's l2: 5493.07\ttraining's RMSLE: 1.00375\tvalid_1's l2: 6204.85\tvalid_1's RMSLE: 0.9455\n",
      "[160]\ttraining's l2: 5049.62\ttraining's RMSLE: 0.972717\tvalid_1's l2: 5747.83\tvalid_1's RMSLE: 0.916449\n",
      "[170]\ttraining's l2: 4662.24\ttraining's RMSLE: 0.943589\tvalid_1's l2: 5342.15\tvalid_1's RMSLE: 0.889268\n",
      "[180]\ttraining's l2: 4327.32\ttraining's RMSLE: 0.916604\tvalid_1's l2: 4987.52\tvalid_1's RMSLE: 0.863997\n",
      "[190]\ttraining's l2: 4038.47\ttraining's RMSLE: 0.889464\tvalid_1's l2: 4679.92\tvalid_1's RMSLE: 0.838712\n",
      "[200]\ttraining's l2: 3774.53\ttraining's RMSLE: 0.863491\tvalid_1's l2: 4395.58\tvalid_1's RMSLE: 0.814475\n",
      "[210]\ttraining's l2: 3552.56\ttraining's RMSLE: 0.839751\tvalid_1's l2: 4159.43\tvalid_1's RMSLE: 0.792555\n",
      "[220]\ttraining's l2: 3356.47\ttraining's RMSLE: 0.816877\tvalid_1's l2: 3949.53\tvalid_1's RMSLE: 0.771487\n",
      "[230]\ttraining's l2: 3172.18\ttraining's RMSLE: 0.795336\tvalid_1's l2: 3748.34\tvalid_1's RMSLE: 0.751448\n",
      "[240]\ttraining's l2: 3004.07\ttraining's RMSLE: 0.774306\tvalid_1's l2: 3566.74\tvalid_1's RMSLE: 0.731977\n",
      "[250]\ttraining's l2: 2846.11\ttraining's RMSLE: 0.754394\tvalid_1's l2: 3390.18\tvalid_1's RMSLE: 0.713665\n",
      "[260]\ttraining's l2: 2717.43\ttraining's RMSLE: 0.73694\tvalid_1's l2: 3249.63\tvalid_1's RMSLE: 0.69769\n",
      "[270]\ttraining's l2: 2598.53\ttraining's RMSLE: 0.720924\tvalid_1's l2: 3126.32\tvalid_1's RMSLE: 0.683348\n",
      "[280]\ttraining's l2: 2493.04\ttraining's RMSLE: 0.704957\tvalid_1's l2: 3015.07\tvalid_1's RMSLE: 0.669082\n",
      "[290]\ttraining's l2: 2403.67\ttraining's RMSLE: 0.69052\tvalid_1's l2: 2921.48\tvalid_1's RMSLE: 0.656054\n",
      "[300]\ttraining's l2: 2317.58\ttraining's RMSLE: 0.675031\tvalid_1's l2: 2832.7\tvalid_1's RMSLE: 0.642241\n",
      "[310]\ttraining's l2: 2238.41\ttraining's RMSLE: 0.66045\tvalid_1's l2: 2749.16\tvalid_1's RMSLE: 0.62924\n",
      "[320]\ttraining's l2: 2164.97\ttraining's RMSLE: 0.645741\tvalid_1's l2: 2676.56\tvalid_1's RMSLE: 0.616384\n",
      "[330]\ttraining's l2: 2101.04\ttraining's RMSLE: 0.632214\tvalid_1's l2: 2609.69\tvalid_1's RMSLE: 0.604259\n",
      "[340]\ttraining's l2: 2039.79\ttraining's RMSLE: 0.620126\tvalid_1's l2: 2543.04\tvalid_1's RMSLE: 0.593221\n",
      "[350]\ttraining's l2: 1979.48\ttraining's RMSLE: 0.607882\tvalid_1's l2: 2478.11\tvalid_1's RMSLE: 0.582199\n",
      "[360]\ttraining's l2: 1933\ttraining's RMSLE: 0.595415\tvalid_1's l2: 2427.74\tvalid_1's RMSLE: 0.571172\n",
      "[370]\ttraining's l2: 1883.79\ttraining's RMSLE: 0.58368\tvalid_1's l2: 2374.56\tvalid_1's RMSLE: 0.560748\n",
      "[380]\ttraining's l2: 1836.06\ttraining's RMSLE: 0.572069\tvalid_1's l2: 2325.12\tvalid_1's RMSLE: 0.550315\n",
      "[390]\ttraining's l2: 1793\ttraining's RMSLE: 0.561317\tvalid_1's l2: 2279.42\tvalid_1's RMSLE: 0.540737\n",
      "[400]\ttraining's l2: 1749.38\ttraining's RMSLE: 0.55044\tvalid_1's l2: 2233.86\tvalid_1's RMSLE: 0.531245\n",
      "[410]\ttraining's l2: 1707.42\ttraining's RMSLE: 0.541102\tvalid_1's l2: 2188.95\tvalid_1's RMSLE: 0.523336\n",
      "[420]\ttraining's l2: 1673.65\ttraining's RMSLE: 0.531962\tvalid_1's l2: 2155.94\tvalid_1's RMSLE: 0.5157\n",
      "[430]\ttraining's l2: 1639.72\ttraining's RMSLE: 0.522837\tvalid_1's l2: 2120.31\tvalid_1's RMSLE: 0.508466\n",
      "[440]\ttraining's l2: 1605.77\ttraining's RMSLE: 0.516051\tvalid_1's l2: 2084.01\tvalid_1's RMSLE: 0.503637\n",
      "[450]\ttraining's l2: 1574.51\ttraining's RMSLE: 0.50896\tvalid_1's l2: 2051.01\tvalid_1's RMSLE: 0.499143\n",
      "[460]\ttraining's l2: 1542.69\ttraining's RMSLE: 0.502693\tvalid_1's l2: 2017.45\tvalid_1's RMSLE: 0.494527\n",
      "[470]\ttraining's l2: 1514.29\ttraining's RMSLE: 0.496269\tvalid_1's l2: 1988.26\tvalid_1's RMSLE: 0.49068\n",
      "[480]\ttraining's l2: 1487.92\ttraining's RMSLE: 0.489681\tvalid_1's l2: 1960.87\tvalid_1's RMSLE: 0.486006\n",
      "[490]\ttraining's l2: 1463.46\ttraining's RMSLE: 0.483489\tvalid_1's l2: 1936.24\tvalid_1's RMSLE: 0.48295\n",
      "[500]\ttraining's l2: 1440.12\ttraining's RMSLE: 0.477902\tvalid_1's l2: 1913.26\tvalid_1's RMSLE: 0.480275\n",
      "[510]\ttraining's l2: 1417.54\ttraining's RMSLE: 0.47323\tvalid_1's l2: 1890.39\tvalid_1's RMSLE: 0.477297\n",
      "[520]\ttraining's l2: 1398.08\ttraining's RMSLE: 0.468711\tvalid_1's l2: 1870.64\tvalid_1's RMSLE: 0.47443\n",
      "[530]\ttraining's l2: 1379.1\ttraining's RMSLE: 0.465385\tvalid_1's l2: 1852.98\tvalid_1's RMSLE: 0.473034\n",
      "[540]\ttraining's l2: 1362.05\ttraining's RMSLE: 0.462411\tvalid_1's l2: 1835.89\tvalid_1's RMSLE: 0.471596\n",
      "[550]\ttraining's l2: 1347.18\ttraining's RMSLE: 0.460959\tvalid_1's l2: 1822.23\tvalid_1's RMSLE: 0.471303\n",
      "[560]\ttraining's l2: 1331.99\ttraining's RMSLE: 0.458921\tvalid_1's l2: 1807.06\tvalid_1's RMSLE: 0.470996\n",
      "[570]\ttraining's l2: 1316.54\ttraining's RMSLE: 0.455523\tvalid_1's l2: 1791.7\tvalid_1's RMSLE: 0.468333\n",
      "[580]\ttraining's l2: 1301.14\ttraining's RMSLE: 0.45186\tvalid_1's l2: 1778.88\tvalid_1's RMSLE: 0.465658\n",
      "[590]\ttraining's l2: 1285.89\ttraining's RMSLE: 0.448125\tvalid_1's l2: 1764.11\tvalid_1's RMSLE: 0.463044\n",
      "[600]\ttraining's l2: 1272.45\ttraining's RMSLE: 0.445688\tvalid_1's l2: 1752.99\tvalid_1's RMSLE: 0.461957\n",
      "[610]\ttraining's l2: 1258.78\ttraining's RMSLE: 0.442564\tvalid_1's l2: 1740.92\tvalid_1's RMSLE: 0.460392\n",
      "[620]\ttraining's l2: 1246.31\ttraining's RMSLE: 0.439633\tvalid_1's l2: 1730.45\tvalid_1's RMSLE: 0.458721\n",
      "[630]\ttraining's l2: 1233.8\ttraining's RMSLE: 0.437424\tvalid_1's l2: 1720.03\tvalid_1's RMSLE: 0.457011\n",
      "[640]\ttraining's l2: 1221\ttraining's RMSLE: 0.433707\tvalid_1's l2: 1708.98\tvalid_1's RMSLE: 0.454105\n",
      "[650]\ttraining's l2: 1208.35\ttraining's RMSLE: 0.430801\tvalid_1's l2: 1698.53\tvalid_1's RMSLE: 0.451324\n",
      "[660]\ttraining's l2: 1197.36\ttraining's RMSLE: 0.428213\tvalid_1's l2: 1690.69\tvalid_1's RMSLE: 0.448885\n",
      "[670]\ttraining's l2: 1187.38\ttraining's RMSLE: 0.426369\tvalid_1's l2: 1682.97\tvalid_1's RMSLE: 0.447363\n",
      "[680]\ttraining's l2: 1177.46\ttraining's RMSLE: 0.424843\tvalid_1's l2: 1676.4\tvalid_1's RMSLE: 0.446301\n",
      "[690]\ttraining's l2: 1167.66\ttraining's RMSLE: 0.423165\tvalid_1's l2: 1669.39\tvalid_1's RMSLE: 0.444656\n",
      "[700]\ttraining's l2: 1158.19\ttraining's RMSLE: 0.421177\tvalid_1's l2: 1661.32\tvalid_1's RMSLE: 0.443459\n",
      "[710]\ttraining's l2: 1149.75\ttraining's RMSLE: 0.420823\tvalid_1's l2: 1655.4\tvalid_1's RMSLE: 0.443057\n",
      "[720]\ttraining's l2: 1140.57\ttraining's RMSLE: 0.420147\tvalid_1's l2: 1649.2\tvalid_1's RMSLE: 0.442562\n",
      "[730]\ttraining's l2: 1131.87\ttraining's RMSLE: 0.418805\tvalid_1's l2: 1643.14\tvalid_1's RMSLE: 0.441517\n",
      "[740]\ttraining's l2: 1123.93\ttraining's RMSLE: 0.418133\tvalid_1's l2: 1637.7\tvalid_1's RMSLE: 0.441131\n",
      "[750]\ttraining's l2: 1115.52\ttraining's RMSLE: 0.416677\tvalid_1's l2: 1632.05\tvalid_1's RMSLE: 0.440065\n",
      "[760]\ttraining's l2: 1106.54\ttraining's RMSLE: 0.414375\tvalid_1's l2: 1625.66\tvalid_1's RMSLE: 0.438153\n",
      "[770]\ttraining's l2: 1097.01\ttraining's RMSLE: 0.411773\tvalid_1's l2: 1617.62\tvalid_1's RMSLE: 0.435924\n",
      "[780]\ttraining's l2: 1088.07\ttraining's RMSLE: 0.409175\tvalid_1's l2: 1610.28\tvalid_1's RMSLE: 0.433555\n",
      "[790]\ttraining's l2: 1080.03\ttraining's RMSLE: 0.407399\tvalid_1's l2: 1604.76\tvalid_1's RMSLE: 0.431871\n",
      "[800]\ttraining's l2: 1072.21\ttraining's RMSLE: 0.405548\tvalid_1's l2: 1598.7\tvalid_1's RMSLE: 0.430232\n",
      "[810]\ttraining's l2: 1064.7\ttraining's RMSLE: 0.404381\tvalid_1's l2: 1592.75\tvalid_1's RMSLE: 0.429144\n",
      "[820]\ttraining's l2: 1057.17\ttraining's RMSLE: 0.402431\tvalid_1's l2: 1587.66\tvalid_1's RMSLE: 0.42776\n",
      "[830]\ttraining's l2: 1050.37\ttraining's RMSLE: 0.401316\tvalid_1's l2: 1583.83\tvalid_1's RMSLE: 0.426668\n",
      "[840]\ttraining's l2: 1043.43\ttraining's RMSLE: 0.40065\tvalid_1's l2: 1580.54\tvalid_1's RMSLE: 0.42595\n",
      "[850]\ttraining's l2: 1035.94\ttraining's RMSLE: 0.398498\tvalid_1's l2: 1575.45\tvalid_1's RMSLE: 0.424653\n",
      "[860]\ttraining's l2: 1028.88\ttraining's RMSLE: 0.397156\tvalid_1's l2: 1570.82\tvalid_1's RMSLE: 0.423444\n",
      "[870]\ttraining's l2: 1020.87\ttraining's RMSLE: 0.395262\tvalid_1's l2: 1565.39\tvalid_1's RMSLE: 0.421309\n",
      "[880]\ttraining's l2: 1013.58\ttraining's RMSLE: 0.393481\tvalid_1's l2: 1560.55\tvalid_1's RMSLE: 0.419225\n",
      "[890]\ttraining's l2: 1006.22\ttraining's RMSLE: 0.392156\tvalid_1's l2: 1555.29\tvalid_1's RMSLE: 0.416996\n",
      "[900]\ttraining's l2: 999.783\ttraining's RMSLE: 0.391721\tvalid_1's l2: 1550.92\tvalid_1's RMSLE: 0.416202\n",
      "[910]\ttraining's l2: 993.71\ttraining's RMSLE: 0.391255\tvalid_1's l2: 1546.97\tvalid_1's RMSLE: 0.415713\n",
      "[920]\ttraining's l2: 988.186\ttraining's RMSLE: 0.390641\tvalid_1's l2: 1543.26\tvalid_1's RMSLE: 0.414586\n",
      "[930]\ttraining's l2: 983.382\ttraining's RMSLE: 0.39017\tvalid_1's l2: 1540.03\tvalid_1's RMSLE: 0.414022\n",
      "[940]\ttraining's l2: 978.369\ttraining's RMSLE: 0.389929\tvalid_1's l2: 1536.89\tvalid_1's RMSLE: 0.413638\n",
      "[950]\ttraining's l2: 973.424\ttraining's RMSLE: 0.389337\tvalid_1's l2: 1533.4\tvalid_1's RMSLE: 0.413198\n",
      "[960]\ttraining's l2: 968.934\ttraining's RMSLE: 0.388512\tvalid_1's l2: 1530.35\tvalid_1's RMSLE: 0.412622\n",
      "[970]\ttraining's l2: 964.488\ttraining's RMSLE: 0.38798\tvalid_1's l2: 1527.64\tvalid_1's RMSLE: 0.41203\n",
      "[980]\ttraining's l2: 959.554\ttraining's RMSLE: 0.387376\tvalid_1's l2: 1524.25\tvalid_1's RMSLE: 0.411457\n",
      "[990]\ttraining's l2: 954.997\ttraining's RMSLE: 0.386949\tvalid_1's l2: 1520.9\tvalid_1's RMSLE: 0.411132\n",
      "[1000]\ttraining's l2: 950.453\ttraining's RMSLE: 0.386605\tvalid_1's l2: 1518.12\tvalid_1's RMSLE: 0.411264\n",
      "Early stopping, best iteration is:\n",
      "[992]\ttraining's l2: 953.997\ttraining's RMSLE: 0.386746\tvalid_1's l2: 1520.24\tvalid_1's RMSLE: 0.410996\n",
      "predict valid for fold 3\n",
      "save model for fold 3\n",
      "start training for fold 4\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 191.757148\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 28238.2\ttraining's RMSLE: 1.50695\tvalid_1's l2: 27767.6\tvalid_1's RMSLE: 1.5533\n",
      "[20]\ttraining's l2: 24318.6\ttraining's RMSLE: 1.45822\tvalid_1's l2: 23928.9\tvalid_1's RMSLE: 1.50371\n",
      "[30]\ttraining's l2: 21054\ttraining's RMSLE: 1.4128\tvalid_1's l2: 20719.5\tvalid_1's RMSLE: 1.45719\n",
      "[40]\ttraining's l2: 18352.5\ttraining's RMSLE: 1.37032\tvalid_1's l2: 18074.6\tvalid_1's RMSLE: 1.41356\n",
      "[50]\ttraining's l2: 16096.8\ttraining's RMSLE: 1.33035\tvalid_1's l2: 15876.9\tvalid_1's RMSLE: 1.37245\n",
      "[60]\ttraining's l2: 14200.2\ttraining's RMSLE: 1.29218\tvalid_1's l2: 14022.1\tvalid_1's RMSLE: 1.333\n",
      "[70]\ttraining's l2: 12602.6\ttraining's RMSLE: 1.25536\tvalid_1's l2: 12451.6\tvalid_1's RMSLE: 1.29479\n",
      "[80]\ttraining's l2: 11242.6\ttraining's RMSLE: 1.2202\tvalid_1's l2: 11122.1\tvalid_1's RMSLE: 1.25831\n",
      "[90]\ttraining's l2: 10102.1\ttraining's RMSLE: 1.18509\tvalid_1's l2: 10001.1\tvalid_1's RMSLE: 1.2218\n",
      "[100]\ttraining's l2: 9091.31\ttraining's RMSLE: 1.15254\tvalid_1's l2: 9021.04\tvalid_1's RMSLE: 1.1882\n",
      "[110]\ttraining's l2: 8121.18\ttraining's RMSLE: 1.11747\tvalid_1's l2: 8073.57\tvalid_1's RMSLE: 1.15189\n",
      "[120]\ttraining's l2: 7311.54\ttraining's RMSLE: 1.08447\tvalid_1's l2: 7286.17\tvalid_1's RMSLE: 1.11785\n",
      "[130]\ttraining's l2: 6611.07\ttraining's RMSLE: 1.05248\tvalid_1's l2: 6599.17\tvalid_1's RMSLE: 1.08488\n",
      "[140]\ttraining's l2: 6013.1\ttraining's RMSLE: 1.02069\tvalid_1's l2: 6027.88\tvalid_1's RMSLE: 1.05214\n",
      "[150]\ttraining's l2: 5496.81\ttraining's RMSLE: 0.990347\tvalid_1's l2: 5538.92\tvalid_1's RMSLE: 1.02089\n",
      "[160]\ttraining's l2: 5053.82\ttraining's RMSLE: 0.960007\tvalid_1's l2: 5118.28\tvalid_1's RMSLE: 0.989587\n",
      "[170]\ttraining's l2: 4666.35\ttraining's RMSLE: 0.931372\tvalid_1's l2: 4747.36\tvalid_1's RMSLE: 0.960082\n",
      "[180]\ttraining's l2: 4338.26\ttraining's RMSLE: 0.903511\tvalid_1's l2: 4437.31\tvalid_1's RMSLE: 0.931292\n",
      "[190]\ttraining's l2: 4042.82\ttraining's RMSLE: 0.877597\tvalid_1's l2: 4154.78\tvalid_1's RMSLE: 0.904567\n",
      "[200]\ttraining's l2: 3794.83\ttraining's RMSLE: 0.85222\tvalid_1's l2: 3917.69\tvalid_1's RMSLE: 0.878367\n",
      "[210]\ttraining's l2: 3573.93\ttraining's RMSLE: 0.828657\tvalid_1's l2: 3709.03\tvalid_1's RMSLE: 0.854112\n",
      "[220]\ttraining's l2: 3372.22\ttraining's RMSLE: 0.806128\tvalid_1's l2: 3515.7\tvalid_1's RMSLE: 0.831001\n",
      "[230]\ttraining's l2: 3189.79\ttraining's RMSLE: 0.784567\tvalid_1's l2: 3340.61\tvalid_1's RMSLE: 0.808867\n",
      "[240]\ttraining's l2: 3027.51\ttraining's RMSLE: 0.764531\tvalid_1's l2: 3188.1\tvalid_1's RMSLE: 0.78838\n",
      "[250]\ttraining's l2: 2886.88\ttraining's RMSLE: 0.745756\tvalid_1's l2: 3056.52\tvalid_1's RMSLE: 0.769254\n",
      "[260]\ttraining's l2: 2753.29\ttraining's RMSLE: 0.729003\tvalid_1's l2: 2927.94\tvalid_1's RMSLE: 0.752262\n",
      "[270]\ttraining's l2: 2640.25\ttraining's RMSLE: 0.712218\tvalid_1's l2: 2825.3\tvalid_1's RMSLE: 0.735141\n",
      "[280]\ttraining's l2: 2537.31\ttraining's RMSLE: 0.696038\tvalid_1's l2: 2726.46\tvalid_1's RMSLE: 0.718542\n",
      "[290]\ttraining's l2: 2441.58\ttraining's RMSLE: 0.680937\tvalid_1's l2: 2636.37\tvalid_1's RMSLE: 0.703199\n",
      "[300]\ttraining's l2: 2358.82\ttraining's RMSLE: 0.665639\tvalid_1's l2: 2564.38\tvalid_1's RMSLE: 0.687479\n",
      "[310]\ttraining's l2: 2280.94\ttraining's RMSLE: 0.650745\tvalid_1's l2: 2492.98\tvalid_1's RMSLE: 0.672238\n",
      "[320]\ttraining's l2: 2213.74\ttraining's RMSLE: 0.63575\tvalid_1's l2: 2433.85\tvalid_1's RMSLE: 0.657096\n",
      "[330]\ttraining's l2: 2152.59\ttraining's RMSLE: 0.621619\tvalid_1's l2: 2381.26\tvalid_1's RMSLE: 0.643307\n",
      "[340]\ttraining's l2: 2087.49\ttraining's RMSLE: 0.608646\tvalid_1's l2: 2318.79\tvalid_1's RMSLE: 0.630268\n",
      "[350]\ttraining's l2: 2019.19\ttraining's RMSLE: 0.5953\tvalid_1's l2: 2251.98\tvalid_1's RMSLE: 0.616887\n",
      "[360]\ttraining's l2: 1962.17\ttraining's RMSLE: 0.582393\tvalid_1's l2: 2199.46\tvalid_1's RMSLE: 0.603648\n",
      "[370]\ttraining's l2: 1908.62\ttraining's RMSLE: 0.571701\tvalid_1's l2: 2151.12\tvalid_1's RMSLE: 0.592826\n",
      "[380]\ttraining's l2: 1861.45\ttraining's RMSLE: 0.56144\tvalid_1's l2: 2109.86\tvalid_1's RMSLE: 0.58229\n",
      "[390]\ttraining's l2: 1817.08\ttraining's RMSLE: 0.551808\tvalid_1's l2: 2070.09\tvalid_1's RMSLE: 0.572314\n",
      "[400]\ttraining's l2: 1773.82\ttraining's RMSLE: 0.541495\tvalid_1's l2: 2029.83\tvalid_1's RMSLE: 0.561435\n",
      "[410]\ttraining's l2: 1734.37\ttraining's RMSLE: 0.531416\tvalid_1's l2: 1992.41\tvalid_1's RMSLE: 0.551014\n",
      "[420]\ttraining's l2: 1698.37\ttraining's RMSLE: 0.522939\tvalid_1's l2: 1959.48\tvalid_1's RMSLE: 0.542328\n",
      "[430]\ttraining's l2: 1664.12\ttraining's RMSLE: 0.514754\tvalid_1's l2: 1926.33\tvalid_1's RMSLE: 0.533575\n",
      "[440]\ttraining's l2: 1631.23\ttraining's RMSLE: 0.50663\tvalid_1's l2: 1895.13\tvalid_1's RMSLE: 0.525116\n",
      "[450]\ttraining's l2: 1601.5\ttraining's RMSLE: 0.498766\tvalid_1's l2: 1869.06\tvalid_1's RMSLE: 0.516815\n",
      "[460]\ttraining's l2: 1572.96\ttraining's RMSLE: 0.492881\tvalid_1's l2: 1845.38\tvalid_1's RMSLE: 0.510664\n",
      "[470]\ttraining's l2: 1545.96\ttraining's RMSLE: 0.487792\tvalid_1's l2: 1823.89\tvalid_1's RMSLE: 0.504893\n",
      "[480]\ttraining's l2: 1520.67\ttraining's RMSLE: 0.483623\tvalid_1's l2: 1801.35\tvalid_1's RMSLE: 0.499558\n",
      "[490]\ttraining's l2: 1497.2\ttraining's RMSLE: 0.478936\tvalid_1's l2: 1782.04\tvalid_1's RMSLE: 0.494051\n",
      "[500]\ttraining's l2: 1475.39\ttraining's RMSLE: 0.474704\tvalid_1's l2: 1765.39\tvalid_1's RMSLE: 0.489409\n",
      "[510]\ttraining's l2: 1454.73\ttraining's RMSLE: 0.471006\tvalid_1's l2: 1749.3\tvalid_1's RMSLE: 0.484995\n",
      "[520]\ttraining's l2: 1435.27\ttraining's RMSLE: 0.465945\tvalid_1's l2: 1734.23\tvalid_1's RMSLE: 0.479848\n",
      "[530]\ttraining's l2: 1416.81\ttraining's RMSLE: 0.46355\tvalid_1's l2: 1719.97\tvalid_1's RMSLE: 0.47744\n",
      "[540]\ttraining's l2: 1400.39\ttraining's RMSLE: 0.460727\tvalid_1's l2: 1708.04\tvalid_1's RMSLE: 0.474474\n",
      "[550]\ttraining's l2: 1383.38\ttraining's RMSLE: 0.457607\tvalid_1's l2: 1694.57\tvalid_1's RMSLE: 0.4711\n",
      "[560]\ttraining's l2: 1368.04\ttraining's RMSLE: 0.455224\tvalid_1's l2: 1682.3\tvalid_1's RMSLE: 0.46861\n",
      "[570]\ttraining's l2: 1352.16\ttraining's RMSLE: 0.452217\tvalid_1's l2: 1670.78\tvalid_1's RMSLE: 0.465274\n",
      "[580]\ttraining's l2: 1336.5\ttraining's RMSLE: 0.448521\tvalid_1's l2: 1658.27\tvalid_1's RMSLE: 0.4614\n",
      "[590]\ttraining's l2: 1321.6\ttraining's RMSLE: 0.446123\tvalid_1's l2: 1646.87\tvalid_1's RMSLE: 0.458841\n",
      "[600]\ttraining's l2: 1307.2\ttraining's RMSLE: 0.443498\tvalid_1's l2: 1635.72\tvalid_1's RMSLE: 0.456152\n",
      "[610]\ttraining's l2: 1293.16\ttraining's RMSLE: 0.440077\tvalid_1's l2: 1626.89\tvalid_1's RMSLE: 0.452671\n",
      "[620]\ttraining's l2: 1279.74\ttraining's RMSLE: 0.436454\tvalid_1's l2: 1617.52\tvalid_1's RMSLE: 0.449063\n",
      "[630]\ttraining's l2: 1266.82\ttraining's RMSLE: 0.434782\tvalid_1's l2: 1608.63\tvalid_1's RMSLE: 0.44775\n",
      "[640]\ttraining's l2: 1255.22\ttraining's RMSLE: 0.433865\tvalid_1's l2: 1600.35\tvalid_1's RMSLE: 0.446793\n",
      "[650]\ttraining's l2: 1243.71\ttraining's RMSLE: 0.432253\tvalid_1's l2: 1593.59\tvalid_1's RMSLE: 0.445015\n",
      "[660]\ttraining's l2: 1233.45\ttraining's RMSLE: 0.431812\tvalid_1's l2: 1588.52\tvalid_1's RMSLE: 0.444544\n",
      "[670]\ttraining's l2: 1223.46\ttraining's RMSLE: 0.431389\tvalid_1's l2: 1582.39\tvalid_1's RMSLE: 0.444555\n",
      "[680]\ttraining's l2: 1213.31\ttraining's RMSLE: 0.43011\tvalid_1's l2: 1577.17\tvalid_1's RMSLE: 0.444015\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's l2: 1220.28\ttraining's RMSLE: 0.430803\tvalid_1's l2: 1580.69\tvalid_1's RMSLE: 0.443899\n",
      "predict valid for fold 4\n",
      "save model for fold 4\n",
      "RMSLE: 0.42527243059731556\n"
     ]
    }
   ],
   "source": [
    "model_path = Path(\"../output/model003\")\n",
    "\n",
    "train_rmsle = train(train_df, model_path)\n",
    "print(f\"RMSLE: {train_rmsle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, model_path):\n",
    "    predictions = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"loading model for fold {fold}\")\n",
    "        model = lgb.Booster(model_file=model_path / f\"model_fold{fold+1:03d}.bin\")\n",
    "\n",
    "        print(f\"start evaluate for fold {fold}\")\n",
    "        X_test = df.copy()\n",
    "\n",
    "        print(f\"predict test for fold {fold}\")\n",
    "        y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        y_pred = np.clip(y_pred, 0, None)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    average_predictions = np.mean(predictions, axis=0)\n",
    "    return average_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model for fold 0\n",
      "start evaluate for fold 0\n",
      "predict test for fold 0\n",
      "loading model for fold 1\n",
      "start evaluate for fold 1\n",
      "predict test for fold 1\n",
      "loading model for fold 2\n",
      "start evaluate for fold 2\n",
      "predict test for fold 2\n",
      "loading model for fold 3\n",
      "start evaluate for fold 3\n",
      "predict test for fold 3\n",
      "loading model for fold 4\n",
      "start evaluate for fold 4\n",
      "predict test for fold 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 14.68089565,   6.76358462,   3.97099437, ..., 123.61753269,\n",
       "        91.00043642,  59.64059941])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = evaluate(test_df, model_path)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(input_path / \"sampleSubmission.csv\")\n",
    "submission[\"count\"] = y_pred\n",
    "submission.to_csv(\"../output/submission003.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lgb.Booster(model_file=model_path / f\"model_fold001.bin\")\n",
    "importance_df = pd.DataFrame()\n",
    "\n",
    "importance_df[\"importance\"] = model.feature_importance(importance_type=\"gain\")\n",
    "importance_df[\"feature_name\"] = model.feature_name()\n",
    "importance_df = importance_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 10))\n",
    "sns.barplot(data=importance_df, x=\"importance\", y=\"feature_name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
