{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exp004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path(\"../input\")\n",
    "\n",
    "train_df = pd.read_parquet(input_path / \"train.parquet\")\n",
    "test_df = pd.read_parquet(input_path / \"test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSLEの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feval_rmsle(preds, data):\n",
    "    y_true = data.get_label()\n",
    "    preds = np.clip(preds, 0, None)  # 0より小さい値を0に置換\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, preds))\n",
    "    return 'RMSLE', rmsle, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0, sort=False).reset_index(drop=True)\n",
    "df = df.drop([\"casual\", \"registered\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = pd.to_datetime(df[\"datetime\"])\n",
    "df[\"year\"] = datetime.dt.year\n",
    "df[\"month\"] = datetime.dt.month\n",
    "df[\"day\"] = datetime.dt.day\n",
    "df[\"hour\"] = datetime.dt.hour\n",
    "df[\"dayofweek\"] = datetime.dt.day_name()\n",
    "df[\"dayofweek\"] = df[\"dayofweek\"].map({\"Monday\": 0, \"Tuesday\": 1, \"Wednesday\": 2, \"Thursday\": 3, \"Friday\": 4, \"Saturday\": 5, \"Sunday\": 6})\n",
    "df = df.drop(\"datetime\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"count\"] = df[\"count\"].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[~df[\"count\"].isnull()].reset_index(drop=True)\n",
    "test_df = df[df[\"count\"].isnull()].drop(\"count\", axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, model_path):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_rmsles = []\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kf.split(df)):\n",
    "        print(f\"start training for fold {fold}\")\n",
    "\n",
    "        X_train = df.iloc[train_index].drop([\"count\"], axis=1)\n",
    "        y_train = df.iloc[train_index][\"count\"]\n",
    "\n",
    "        X_valid = df.iloc[valid_index].drop([\"count\"], axis=1)\n",
    "        y_valid = df.iloc[valid_index][\"count\"]\n",
    "\n",
    "        print(\"start training\")\n",
    "        params = {\n",
    "            \"objective\": \"regression\",\n",
    "            \"seed\": 42,\n",
    "            \"learning_rate\": 0.01,\n",
    "            \"num_leaves\": 32,\n",
    "        }\n",
    "\n",
    "        train_set = lgb.Dataset(X_train, y_train)\n",
    "        valid_set = lgb.Dataset(X_valid, y_valid, reference=train_set)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params=params,\n",
    "            train_set=train_set,\n",
    "            valid_sets=[train_set, valid_set],\n",
    "            num_boost_round=10000,\n",
    "            feval=feval_rmsle,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=10, verbose=True),\n",
    "                lgb.log_evaluation(period=10)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(f\"predict valid for fold {fold}\")\n",
    "        y_pred = model.predict(X_valid)\n",
    "        y_pred = np.clip(y_pred, 0, None)\n",
    "        y_pred = np.exp(y_pred)\n",
    "        y_valid = np.exp(y_valid)\n",
    "\n",
    "        fold_rmsles.append(np.sqrt(mean_squared_log_error(y_valid, y_pred)))\n",
    "\n",
    "        print(f\"save model for fold {fold}\")\n",
    "        model.save_model(model_path / f\"model_fold{fold+1:03d}.bin\", num_iteration=model.best_iteration)\n",
    "\n",
    "    return sum(fold_rmsles) / len(fold_rmsles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training for fold 0\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 8708, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 4.555325\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 1.86485\ttraining's RMSLE: 0.337259\tvalid_1's l2: 1.92404\tvalid_1's RMSLE: 0.346296\n",
      "[20]\ttraining's l2: 1.58642\ttraining's RMSLE: 0.318099\tvalid_1's l2: 1.6399\tvalid_1's RMSLE: 0.32701\n",
      "[30]\ttraining's l2: 1.35702\ttraining's RMSLE: 0.300501\tvalid_1's l2: 1.40639\tvalid_1's RMSLE: 0.309373\n",
      "[40]\ttraining's l2: 1.16716\ttraining's RMSLE: 0.284341\tvalid_1's l2: 1.21319\tvalid_1's RMSLE: 0.293187\n",
      "[50]\ttraining's l2: 1.00992\ttraining's RMSLE: 0.26945\tvalid_1's l2: 1.05244\tvalid_1's RMSLE: 0.278198\n",
      "[60]\ttraining's l2: 0.878865\ttraining's RMSLE: 0.255615\tvalid_1's l2: 0.91805\tvalid_1's RMSLE: 0.264196\n",
      "[70]\ttraining's l2: 0.769314\ttraining's RMSLE: 0.242826\tvalid_1's l2: 0.804612\tvalid_1's RMSLE: 0.251076\n",
      "[80]\ttraining's l2: 0.678039\ttraining's RMSLE: 0.231221\tvalid_1's l2: 0.71041\tvalid_1's RMSLE: 0.239218\n",
      "[90]\ttraining's l2: 0.601436\ttraining's RMSLE: 0.220932\tvalid_1's l2: 0.631997\tvalid_1's RMSLE: 0.228876\n",
      "[100]\ttraining's l2: 0.536344\ttraining's RMSLE: 0.211282\tvalid_1's l2: 0.564879\tvalid_1's RMSLE: 0.219\n",
      "[110]\ttraining's l2: 0.479985\ttraining's RMSLE: 0.202398\tvalid_1's l2: 0.506961\tvalid_1's RMSLE: 0.209999\n",
      "[120]\ttraining's l2: 0.433311\ttraining's RMSLE: 0.194362\tvalid_1's l2: 0.459335\tvalid_1's RMSLE: 0.201928\n",
      "[130]\ttraining's l2: 0.393003\ttraining's RMSLE: 0.186979\tvalid_1's l2: 0.417942\tvalid_1's RMSLE: 0.194459\n",
      "[140]\ttraining's l2: 0.358348\ttraining's RMSLE: 0.18021\tvalid_1's l2: 0.382472\tvalid_1's RMSLE: 0.187645\n",
      "[150]\ttraining's l2: 0.328491\ttraining's RMSLE: 0.174119\tvalid_1's l2: 0.351685\tvalid_1's RMSLE: 0.181493\n",
      "[160]\ttraining's l2: 0.302876\ttraining's RMSLE: 0.168511\tvalid_1's l2: 0.325412\tvalid_1's RMSLE: 0.175854\n",
      "[170]\ttraining's l2: 0.280145\ttraining's RMSLE: 0.163315\tvalid_1's l2: 0.302336\tvalid_1's RMSLE: 0.170693\n",
      "[180]\ttraining's l2: 0.258989\ttraining's RMSLE: 0.158634\tvalid_1's l2: 0.280619\tvalid_1's RMSLE: 0.165979\n",
      "[190]\ttraining's l2: 0.240679\ttraining's RMSLE: 0.154202\tvalid_1's l2: 0.261743\tvalid_1's RMSLE: 0.161498\n",
      "[200]\ttraining's l2: 0.224609\ttraining's RMSLE: 0.150331\tvalid_1's l2: 0.245353\tvalid_1's RMSLE: 0.157665\n",
      "[210]\ttraining's l2: 0.210662\ttraining's RMSLE: 0.146686\tvalid_1's l2: 0.23108\tvalid_1's RMSLE: 0.154025\n",
      "[220]\ttraining's l2: 0.198882\ttraining's RMSLE: 0.143244\tvalid_1's l2: 0.219209\tvalid_1's RMSLE: 0.150625\n",
      "[230]\ttraining's l2: 0.188311\ttraining's RMSLE: 0.140159\tvalid_1's l2: 0.208485\tvalid_1's RMSLE: 0.147584\n",
      "[240]\ttraining's l2: 0.179166\ttraining's RMSLE: 0.137133\tvalid_1's l2: 0.199428\tvalid_1's RMSLE: 0.144647\n",
      "[250]\ttraining's l2: 0.170465\ttraining's RMSLE: 0.134368\tvalid_1's l2: 0.190676\tvalid_1's RMSLE: 0.141911\n",
      "[260]\ttraining's l2: 0.162563\ttraining's RMSLE: 0.131708\tvalid_1's l2: 0.182711\tvalid_1's RMSLE: 0.139341\n",
      "[270]\ttraining's l2: 0.155854\ttraining's RMSLE: 0.129356\tvalid_1's l2: 0.176069\tvalid_1's RMSLE: 0.137108\n",
      "[280]\ttraining's l2: 0.150074\ttraining's RMSLE: 0.127235\tvalid_1's l2: 0.170619\tvalid_1's RMSLE: 0.135185\n",
      "[290]\ttraining's l2: 0.144658\ttraining's RMSLE: 0.125284\tvalid_1's l2: 0.165302\tvalid_1's RMSLE: 0.133392\n",
      "[300]\ttraining's l2: 0.139695\ttraining's RMSLE: 0.123428\tvalid_1's l2: 0.160499\tvalid_1's RMSLE: 0.131672\n",
      "[310]\ttraining's l2: 0.135386\ttraining's RMSLE: 0.121757\tvalid_1's l2: 0.156245\tvalid_1's RMSLE: 0.130128\n",
      "[320]\ttraining's l2: 0.131349\ttraining's RMSLE: 0.120162\tvalid_1's l2: 0.152317\tvalid_1's RMSLE: 0.12866\n",
      "[330]\ttraining's l2: 0.127836\ttraining's RMSLE: 0.118766\tvalid_1's l2: 0.149052\tvalid_1's RMSLE: 0.127453\n",
      "[340]\ttraining's l2: 0.124427\ttraining's RMSLE: 0.11747\tvalid_1's l2: 0.145857\tvalid_1's RMSLE: 0.126325\n",
      "[350]\ttraining's l2: 0.121383\ttraining's RMSLE: 0.116246\tvalid_1's l2: 0.142953\tvalid_1's RMSLE: 0.125275\n",
      "[360]\ttraining's l2: 0.118625\ttraining's RMSLE: 0.115127\tvalid_1's l2: 0.140517\tvalid_1's RMSLE: 0.124367\n",
      "[370]\ttraining's l2: 0.116182\ttraining's RMSLE: 0.114078\tvalid_1's l2: 0.138438\tvalid_1's RMSLE: 0.123547\n",
      "[380]\ttraining's l2: 0.113644\ttraining's RMSLE: 0.113006\tvalid_1's l2: 0.136189\tvalid_1's RMSLE: 0.122688\n",
      "[390]\ttraining's l2: 0.111197\ttraining's RMSLE: 0.111931\tvalid_1's l2: 0.134018\tvalid_1's RMSLE: 0.121861\n",
      "[400]\ttraining's l2: 0.108865\ttraining's RMSLE: 0.110886\tvalid_1's l2: 0.131871\tvalid_1's RMSLE: 0.12101\n",
      "[410]\ttraining's l2: 0.107117\ttraining's RMSLE: 0.109978\tvalid_1's l2: 0.130512\tvalid_1's RMSLE: 0.120415\n",
      "[420]\ttraining's l2: 0.105395\ttraining's RMSLE: 0.109145\tvalid_1's l2: 0.12928\tvalid_1's RMSLE: 0.119958\n",
      "[430]\ttraining's l2: 0.103384\ttraining's RMSLE: 0.108232\tvalid_1's l2: 0.127339\tvalid_1's RMSLE: 0.119201\n",
      "[440]\ttraining's l2: 0.101733\ttraining's RMSLE: 0.107489\tvalid_1's l2: 0.125935\tvalid_1's RMSLE: 0.118649\n",
      "[450]\ttraining's l2: 0.100251\ttraining's RMSLE: 0.106809\tvalid_1's l2: 0.124807\tvalid_1's RMSLE: 0.11813\n",
      "[460]\ttraining's l2: 0.0987108\ttraining's RMSLE: 0.106158\tvalid_1's l2: 0.123557\tvalid_1's RMSLE: 0.117624\n",
      "[470]\ttraining's l2: 0.097403\ttraining's RMSLE: 0.105573\tvalid_1's l2: 0.122656\tvalid_1's RMSLE: 0.117229\n",
      "[480]\ttraining's l2: 0.0960985\ttraining's RMSLE: 0.104989\tvalid_1's l2: 0.121657\tvalid_1's RMSLE: 0.116825\n",
      "[490]\ttraining's l2: 0.0950968\ttraining's RMSLE: 0.104493\tvalid_1's l2: 0.121047\tvalid_1's RMSLE: 0.116518\n",
      "[500]\ttraining's l2: 0.0940846\ttraining's RMSLE: 0.104032\tvalid_1's l2: 0.120363\tvalid_1's RMSLE: 0.116235\n",
      "[510]\ttraining's l2: 0.0930223\ttraining's RMSLE: 0.103566\tvalid_1's l2: 0.11947\tvalid_1's RMSLE: 0.115891\n",
      "[520]\ttraining's l2: 0.0921578\ttraining's RMSLE: 0.103134\tvalid_1's l2: 0.118942\tvalid_1's RMSLE: 0.11565\n",
      "[530]\ttraining's l2: 0.0912523\ttraining's RMSLE: 0.102656\tvalid_1's l2: 0.118418\tvalid_1's RMSLE: 0.115424\n",
      "[540]\ttraining's l2: 0.0900605\ttraining's RMSLE: 0.102074\tvalid_1's l2: 0.117494\tvalid_1's RMSLE: 0.115056\n",
      "[550]\ttraining's l2: 0.0889587\ttraining's RMSLE: 0.101521\tvalid_1's l2: 0.116645\tvalid_1's RMSLE: 0.114704\n",
      "[560]\ttraining's l2: 0.0880661\ttraining's RMSLE: 0.101094\tvalid_1's l2: 0.116056\tvalid_1's RMSLE: 0.114464\n",
      "[570]\ttraining's l2: 0.0871098\ttraining's RMSLE: 0.100628\tvalid_1's l2: 0.115253\tvalid_1's RMSLE: 0.114139\n",
      "[580]\ttraining's l2: 0.0863142\ttraining's RMSLE: 0.100211\tvalid_1's l2: 0.114701\tvalid_1's RMSLE: 0.113888\n",
      "[590]\ttraining's l2: 0.0855917\ttraining's RMSLE: 0.0998626\tvalid_1's l2: 0.114244\tvalid_1's RMSLE: 0.113688\n",
      "[600]\ttraining's l2: 0.0847824\ttraining's RMSLE: 0.0994865\tvalid_1's l2: 0.113657\tvalid_1's RMSLE: 0.113468\n",
      "[610]\ttraining's l2: 0.0840596\ttraining's RMSLE: 0.0991114\tvalid_1's l2: 0.113145\tvalid_1's RMSLE: 0.11326\n",
      "[620]\ttraining's l2: 0.0832899\ttraining's RMSLE: 0.0987412\tvalid_1's l2: 0.112529\tvalid_1's RMSLE: 0.113025\n",
      "[630]\ttraining's l2: 0.0825975\ttraining's RMSLE: 0.0983754\tvalid_1's l2: 0.112023\tvalid_1's RMSLE: 0.112811\n",
      "[640]\ttraining's l2: 0.0818893\ttraining's RMSLE: 0.0980673\tvalid_1's l2: 0.111533\tvalid_1's RMSLE: 0.112662\n",
      "[650]\ttraining's l2: 0.0812827\ttraining's RMSLE: 0.0977903\tvalid_1's l2: 0.111105\tvalid_1's RMSLE: 0.112483\n",
      "[660]\ttraining's l2: 0.0806933\ttraining's RMSLE: 0.0975293\tvalid_1's l2: 0.110682\tvalid_1's RMSLE: 0.112336\n",
      "[670]\ttraining's l2: 0.080075\ttraining's RMSLE: 0.0972295\tvalid_1's l2: 0.110246\tvalid_1's RMSLE: 0.112155\n",
      "[680]\ttraining's l2: 0.0795396\ttraining's RMSLE: 0.0969501\tvalid_1's l2: 0.109884\tvalid_1's RMSLE: 0.112057\n",
      "[690]\ttraining's l2: 0.0790887\ttraining's RMSLE: 0.0967295\tvalid_1's l2: 0.109619\tvalid_1's RMSLE: 0.111955\n",
      "[700]\ttraining's l2: 0.0786182\ttraining's RMSLE: 0.0964918\tvalid_1's l2: 0.109422\tvalid_1's RMSLE: 0.111884\n",
      "[710]\ttraining's l2: 0.0781983\ttraining's RMSLE: 0.0962548\tvalid_1's l2: 0.109274\tvalid_1's RMSLE: 0.111862\n",
      "[720]\ttraining's l2: 0.0777771\ttraining's RMSLE: 0.0959975\tvalid_1's l2: 0.109042\tvalid_1's RMSLE: 0.11177\n",
      "[730]\ttraining's l2: 0.0773705\ttraining's RMSLE: 0.0957936\tvalid_1's l2: 0.108843\tvalid_1's RMSLE: 0.111718\n",
      "[740]\ttraining's l2: 0.0768943\ttraining's RMSLE: 0.0955587\tvalid_1's l2: 0.108522\tvalid_1's RMSLE: 0.111585\n",
      "[750]\ttraining's l2: 0.0764659\ttraining's RMSLE: 0.0953405\tvalid_1's l2: 0.10825\tvalid_1's RMSLE: 0.111497\n",
      "[760]\ttraining's l2: 0.0759935\ttraining's RMSLE: 0.095099\tvalid_1's l2: 0.108005\tvalid_1's RMSLE: 0.111415\n",
      "[770]\ttraining's l2: 0.0754982\ttraining's RMSLE: 0.0948321\tvalid_1's l2: 0.107631\tvalid_1's RMSLE: 0.111283\n",
      "[780]\ttraining's l2: 0.0749791\ttraining's RMSLE: 0.0945468\tvalid_1's l2: 0.107242\tvalid_1's RMSLE: 0.111137\n",
      "[790]\ttraining's l2: 0.0744987\ttraining's RMSLE: 0.0942958\tvalid_1's l2: 0.106926\tvalid_1's RMSLE: 0.111039\n",
      "[800]\ttraining's l2: 0.0740524\ttraining's RMSLE: 0.0940341\tvalid_1's l2: 0.10663\tvalid_1's RMSLE: 0.110914\n",
      "[810]\ttraining's l2: 0.0736109\ttraining's RMSLE: 0.0937817\tvalid_1's l2: 0.106376\tvalid_1's RMSLE: 0.110826\n",
      "[820]\ttraining's l2: 0.0732172\ttraining's RMSLE: 0.0935445\tvalid_1's l2: 0.106179\tvalid_1's RMSLE: 0.110749\n",
      "[830]\ttraining's l2: 0.072838\ttraining's RMSLE: 0.0933349\tvalid_1's l2: 0.105982\tvalid_1's RMSLE: 0.110689\n",
      "[840]\ttraining's l2: 0.0724832\ttraining's RMSLE: 0.0931639\tvalid_1's l2: 0.105759\tvalid_1's RMSLE: 0.110626\n",
      "[850]\ttraining's l2: 0.0721271\ttraining's RMSLE: 0.0930083\tvalid_1's l2: 0.105528\tvalid_1's RMSLE: 0.110573\n",
      "[860]\ttraining's l2: 0.0717971\ttraining's RMSLE: 0.092815\tvalid_1's l2: 0.105296\tvalid_1's RMSLE: 0.110492\n",
      "[870]\ttraining's l2: 0.0714933\ttraining's RMSLE: 0.0926737\tvalid_1's l2: 0.105133\tvalid_1's RMSLE: 0.110468\n",
      "[880]\ttraining's l2: 0.0712242\ttraining's RMSLE: 0.0925501\tvalid_1's l2: 0.104984\tvalid_1's RMSLE: 0.110453\n",
      "[890]\ttraining's l2: 0.0708942\ttraining's RMSLE: 0.0923637\tvalid_1's l2: 0.104732\tvalid_1's RMSLE: 0.110355\n",
      "[900]\ttraining's l2: 0.070607\ttraining's RMSLE: 0.0922143\tvalid_1's l2: 0.104564\tvalid_1's RMSLE: 0.110317\n",
      "[910]\ttraining's l2: 0.0702985\ttraining's RMSLE: 0.0920405\tvalid_1's l2: 0.10437\tvalid_1's RMSLE: 0.110229\n",
      "[920]\ttraining's l2: 0.0699696\ttraining's RMSLE: 0.0918514\tvalid_1's l2: 0.104175\tvalid_1's RMSLE: 0.110149\n",
      "[930]\ttraining's l2: 0.0696809\ttraining's RMSLE: 0.0916704\tvalid_1's l2: 0.10405\tvalid_1's RMSLE: 0.110109\n",
      "[940]\ttraining's l2: 0.0693747\ttraining's RMSLE: 0.0914679\tvalid_1's l2: 0.103859\tvalid_1's RMSLE: 0.110026\n",
      "[950]\ttraining's l2: 0.0690451\ttraining's RMSLE: 0.0912439\tvalid_1's l2: 0.103658\tvalid_1's RMSLE: 0.109946\n",
      "[960]\ttraining's l2: 0.0687567\ttraining's RMSLE: 0.0910874\tvalid_1's l2: 0.103471\tvalid_1's RMSLE: 0.109901\n",
      "[970]\ttraining's l2: 0.0684483\ttraining's RMSLE: 0.0909006\tvalid_1's l2: 0.103267\tvalid_1's RMSLE: 0.109835\n",
      "[980]\ttraining's l2: 0.0681917\ttraining's RMSLE: 0.090735\tvalid_1's l2: 0.103169\tvalid_1's RMSLE: 0.109809\n",
      "[990]\ttraining's l2: 0.0679146\ttraining's RMSLE: 0.0905828\tvalid_1's l2: 0.102974\tvalid_1's RMSLE: 0.109759\n",
      "[1000]\ttraining's l2: 0.0676588\ttraining's RMSLE: 0.0904477\tvalid_1's l2: 0.10282\tvalid_1's RMSLE: 0.109719\n",
      "[1010]\ttraining's l2: 0.0674343\ttraining's RMSLE: 0.0903321\tvalid_1's l2: 0.102683\tvalid_1's RMSLE: 0.109693\n",
      "[1020]\ttraining's l2: 0.0671792\ttraining's RMSLE: 0.0901819\tvalid_1's l2: 0.102537\tvalid_1's RMSLE: 0.109657\n",
      "[1030]\ttraining's l2: 0.0669316\ttraining's RMSLE: 0.0900665\tvalid_1's l2: 0.10242\tvalid_1's RMSLE: 0.109624\n",
      "[1040]\ttraining's l2: 0.0666905\ttraining's RMSLE: 0.089929\tvalid_1's l2: 0.102328\tvalid_1's RMSLE: 0.109603\n",
      "[1050]\ttraining's l2: 0.0664443\ttraining's RMSLE: 0.0898137\tvalid_1's l2: 0.102191\tvalid_1's RMSLE: 0.109569\n",
      "[1060]\ttraining's l2: 0.0662008\ttraining's RMSLE: 0.0896908\tvalid_1's l2: 0.102034\tvalid_1's RMSLE: 0.109523\n",
      "[1070]\ttraining's l2: 0.0659675\ttraining's RMSLE: 0.0895587\tvalid_1's l2: 0.101915\tvalid_1's RMSLE: 0.109483\n",
      "[1080]\ttraining's l2: 0.0657438\ttraining's RMSLE: 0.0894255\tvalid_1's l2: 0.101803\tvalid_1's RMSLE: 0.109439\n",
      "[1090]\ttraining's l2: 0.0654998\ttraining's RMSLE: 0.0893238\tvalid_1's l2: 0.101715\tvalid_1's RMSLE: 0.109419\n",
      "[1100]\ttraining's l2: 0.0652461\ttraining's RMSLE: 0.0891663\tvalid_1's l2: 0.101649\tvalid_1's RMSLE: 0.109383\n",
      "[1110]\ttraining's l2: 0.0649942\ttraining's RMSLE: 0.088993\tvalid_1's l2: 0.101593\tvalid_1's RMSLE: 0.10935\n",
      "[1120]\ttraining's l2: 0.0647442\ttraining's RMSLE: 0.0888434\tvalid_1's l2: 0.101541\tvalid_1's RMSLE: 0.109341\n",
      "[1130]\ttraining's l2: 0.0645044\ttraining's RMSLE: 0.0886878\tvalid_1's l2: 0.101497\tvalid_1's RMSLE: 0.10932\n",
      "[1140]\ttraining's l2: 0.0642789\ttraining's RMSLE: 0.0885785\tvalid_1's l2: 0.101399\tvalid_1's RMSLE: 0.109291\n",
      "[1150]\ttraining's l2: 0.0640783\ttraining's RMSLE: 0.0884852\tvalid_1's l2: 0.10131\tvalid_1's RMSLE: 0.109278\n",
      "[1160]\ttraining's l2: 0.0638892\ttraining's RMSLE: 0.0883896\tvalid_1's l2: 0.101232\tvalid_1's RMSLE: 0.109251\n",
      "[1170]\ttraining's l2: 0.0637067\ttraining's RMSLE: 0.0882778\tvalid_1's l2: 0.10117\tvalid_1's RMSLE: 0.109224\n",
      "[1180]\ttraining's l2: 0.0635032\ttraining's RMSLE: 0.0881628\tvalid_1's l2: 0.101112\tvalid_1's RMSLE: 0.109215\n",
      "[1190]\ttraining's l2: 0.0633117\ttraining's RMSLE: 0.0880564\tvalid_1's l2: 0.101046\tvalid_1's RMSLE: 0.109188\n",
      "[1200]\ttraining's l2: 0.0630961\ttraining's RMSLE: 0.0879179\tvalid_1's l2: 0.101083\tvalid_1's RMSLE: 0.109193\n",
      "Early stopping, best iteration is:\n",
      "[1190]\ttraining's l2: 0.0633117\ttraining's RMSLE: 0.0880564\tvalid_1's l2: 0.101046\tvalid_1's RMSLE: 0.109188\n",
      "predict valid for fold 0\n",
      "save model for fold 0\n",
      "start training for fold 1\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 296\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 4.552386\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 1.88726\ttraining's RMSLE: 0.341095\tvalid_1's l2: 1.82751\tvalid_1's RMSLE: 0.330075\n",
      "[20]\ttraining's l2: 1.60366\ttraining's RMSLE: 0.321677\tvalid_1's l2: 1.5572\tvalid_1's RMSLE: 0.311186\n",
      "[30]\ttraining's l2: 1.37033\ttraining's RMSLE: 0.303801\tvalid_1's l2: 1.33417\tvalid_1's RMSLE: 0.293746\n",
      "[40]\ttraining's l2: 1.17749\ttraining's RMSLE: 0.287356\tvalid_1's l2: 1.1498\tvalid_1's RMSLE: 0.277718\n",
      "[50]\ttraining's l2: 1.01822\ttraining's RMSLE: 0.272309\tvalid_1's l2: 0.997789\tvalid_1's RMSLE: 0.26306\n",
      "[60]\ttraining's l2: 0.88502\ttraining's RMSLE: 0.258394\tvalid_1's l2: 0.870383\tvalid_1's RMSLE: 0.249512\n",
      "[70]\ttraining's l2: 0.773382\ttraining's RMSLE: 0.245507\tvalid_1's l2: 0.764292\tvalid_1's RMSLE: 0.237062\n",
      "[80]\ttraining's l2: 0.6811\ttraining's RMSLE: 0.234044\tvalid_1's l2: 0.676013\tvalid_1's RMSLE: 0.225867\n",
      "[90]\ttraining's l2: 0.604086\ttraining's RMSLE: 0.223551\tvalid_1's l2: 0.602464\tvalid_1's RMSLE: 0.215657\n",
      "[100]\ttraining's l2: 0.539637\ttraining's RMSLE: 0.213966\tvalid_1's l2: 0.541446\tvalid_1's RMSLE: 0.206422\n",
      "[110]\ttraining's l2: 0.484669\ttraining's RMSLE: 0.205064\tvalid_1's l2: 0.489099\tvalid_1's RMSLE: 0.19784\n",
      "[120]\ttraining's l2: 0.43813\ttraining's RMSLE: 0.197058\tvalid_1's l2: 0.444182\tvalid_1's RMSLE: 0.19004\n",
      "[130]\ttraining's l2: 0.398838\ttraining's RMSLE: 0.189769\tvalid_1's l2: 0.40662\tvalid_1's RMSLE: 0.183014\n",
      "[140]\ttraining's l2: 0.364711\ttraining's RMSLE: 0.182847\tvalid_1's l2: 0.37405\tvalid_1's RMSLE: 0.176439\n",
      "[150]\ttraining's l2: 0.334538\ttraining's RMSLE: 0.176465\tvalid_1's l2: 0.345125\tvalid_1's RMSLE: 0.170416\n",
      "[160]\ttraining's l2: 0.308769\ttraining's RMSLE: 0.170774\tvalid_1's l2: 0.320349\tvalid_1's RMSLE: 0.165004\n",
      "[170]\ttraining's l2: 0.285354\ttraining's RMSLE: 0.165279\tvalid_1's l2: 0.297478\tvalid_1's RMSLE: 0.159808\n",
      "[180]\ttraining's l2: 0.264884\ttraining's RMSLE: 0.160356\tvalid_1's l2: 0.277471\tvalid_1's RMSLE: 0.155128\n",
      "[190]\ttraining's l2: 0.245165\ttraining's RMSLE: 0.155751\tvalid_1's l2: 0.257536\tvalid_1's RMSLE: 0.150699\n",
      "[200]\ttraining's l2: 0.227776\ttraining's RMSLE: 0.151583\tvalid_1's l2: 0.239748\tvalid_1's RMSLE: 0.146665\n",
      "[210]\ttraining's l2: 0.213543\ttraining's RMSLE: 0.147745\tvalid_1's l2: 0.225457\tvalid_1's RMSLE: 0.143019\n",
      "[220]\ttraining's l2: 0.201166\ttraining's RMSLE: 0.14435\tvalid_1's l2: 0.21298\tvalid_1's RMSLE: 0.139805\n",
      "[230]\ttraining's l2: 0.190315\ttraining's RMSLE: 0.141118\tvalid_1's l2: 0.201994\tvalid_1's RMSLE: 0.136756\n",
      "[240]\ttraining's l2: 0.180586\ttraining's RMSLE: 0.138195\tvalid_1's l2: 0.192133\tvalid_1's RMSLE: 0.134037\n",
      "[250]\ttraining's l2: 0.172067\ttraining's RMSLE: 0.135592\tvalid_1's l2: 0.183625\tvalid_1's RMSLE: 0.131623\n",
      "[260]\ttraining's l2: 0.164456\ttraining's RMSLE: 0.133144\tvalid_1's l2: 0.175982\tvalid_1's RMSLE: 0.129384\n",
      "[270]\ttraining's l2: 0.157863\ttraining's RMSLE: 0.130817\tvalid_1's l2: 0.169635\tvalid_1's RMSLE: 0.127386\n",
      "[280]\ttraining's l2: 0.152033\ttraining's RMSLE: 0.128677\tvalid_1's l2: 0.16396\tvalid_1's RMSLE: 0.125547\n",
      "[290]\ttraining's l2: 0.146695\ttraining's RMSLE: 0.1267\tvalid_1's l2: 0.158755\tvalid_1's RMSLE: 0.123879\n",
      "[300]\ttraining's l2: 0.141899\ttraining's RMSLE: 0.124972\tvalid_1's l2: 0.154057\tvalid_1's RMSLE: 0.122459\n",
      "[310]\ttraining's l2: 0.137572\ttraining's RMSLE: 0.123333\tvalid_1's l2: 0.149902\tvalid_1's RMSLE: 0.121133\n",
      "[320]\ttraining's l2: 0.133626\ttraining's RMSLE: 0.121724\tvalid_1's l2: 0.146107\tvalid_1's RMSLE: 0.11988\n",
      "[330]\ttraining's l2: 0.130187\ttraining's RMSLE: 0.120337\tvalid_1's l2: 0.142779\tvalid_1's RMSLE: 0.118787\n",
      "[340]\ttraining's l2: 0.126596\ttraining's RMSLE: 0.118755\tvalid_1's l2: 0.139433\tvalid_1's RMSLE: 0.117589\n",
      "[350]\ttraining's l2: 0.123264\ttraining's RMSLE: 0.117351\tvalid_1's l2: 0.136269\tvalid_1's RMSLE: 0.11645\n",
      "[360]\ttraining's l2: 0.119967\ttraining's RMSLE: 0.116\tvalid_1's l2: 0.133128\tvalid_1's RMSLE: 0.115388\n",
      "[370]\ttraining's l2: 0.117379\ttraining's RMSLE: 0.114723\tvalid_1's l2: 0.130755\tvalid_1's RMSLE: 0.114441\n",
      "[380]\ttraining's l2: 0.11443\ttraining's RMSLE: 0.113588\tvalid_1's l2: 0.127778\tvalid_1's RMSLE: 0.113539\n",
      "[390]\ttraining's l2: 0.111913\ttraining's RMSLE: 0.1126\tvalid_1's l2: 0.125362\tvalid_1's RMSLE: 0.112821\n",
      "[400]\ttraining's l2: 0.109967\ttraining's RMSLE: 0.111599\tvalid_1's l2: 0.123728\tvalid_1's RMSLE: 0.112181\n",
      "[410]\ttraining's l2: 0.108083\ttraining's RMSLE: 0.110714\tvalid_1's l2: 0.122071\tvalid_1's RMSLE: 0.111592\n",
      "[420]\ttraining's l2: 0.106165\ttraining's RMSLE: 0.109868\tvalid_1's l2: 0.120351\tvalid_1's RMSLE: 0.111019\n",
      "[430]\ttraining's l2: 0.104778\ttraining's RMSLE: 0.109103\tvalid_1's l2: 0.119301\tvalid_1's RMSLE: 0.110587\n",
      "[440]\ttraining's l2: 0.103284\ttraining's RMSLE: 0.108346\tvalid_1's l2: 0.118086\tvalid_1's RMSLE: 0.110157\n",
      "[450]\ttraining's l2: 0.101978\ttraining's RMSLE: 0.10773\tvalid_1's l2: 0.11705\tvalid_1's RMSLE: 0.109798\n",
      "[460]\ttraining's l2: 0.100666\ttraining's RMSLE: 0.107136\tvalid_1's l2: 0.116011\tvalid_1's RMSLE: 0.109463\n",
      "[470]\ttraining's l2: 0.0993061\ttraining's RMSLE: 0.106496\tvalid_1's l2: 0.114929\tvalid_1's RMSLE: 0.109116\n",
      "[480]\ttraining's l2: 0.0983191\ttraining's RMSLE: 0.105926\tvalid_1's l2: 0.11431\tvalid_1's RMSLE: 0.108844\n",
      "[490]\ttraining's l2: 0.097232\ttraining's RMSLE: 0.105428\tvalid_1's l2: 0.113441\tvalid_1's RMSLE: 0.108554\n",
      "[500]\ttraining's l2: 0.096202\ttraining's RMSLE: 0.104965\tvalid_1's l2: 0.112653\tvalid_1's RMSLE: 0.108308\n",
      "[510]\ttraining's l2: 0.0952344\ttraining's RMSLE: 0.104535\tvalid_1's l2: 0.111876\tvalid_1's RMSLE: 0.108059\n",
      "[520]\ttraining's l2: 0.0941507\ttraining's RMSLE: 0.104085\tvalid_1's l2: 0.110921\tvalid_1's RMSLE: 0.107778\n",
      "[530]\ttraining's l2: 0.0930964\ttraining's RMSLE: 0.103589\tvalid_1's l2: 0.110106\tvalid_1's RMSLE: 0.107498\n",
      "[540]\ttraining's l2: 0.0919321\ttraining's RMSLE: 0.103066\tvalid_1's l2: 0.109117\tvalid_1's RMSLE: 0.107211\n",
      "[550]\ttraining's l2: 0.0909622\ttraining's RMSLE: 0.102583\tvalid_1's l2: 0.108401\tvalid_1's RMSLE: 0.106994\n",
      "[560]\ttraining's l2: 0.0900155\ttraining's RMSLE: 0.102078\tvalid_1's l2: 0.107693\tvalid_1's RMSLE: 0.106763\n",
      "[570]\ttraining's l2: 0.0891995\ttraining's RMSLE: 0.101626\tvalid_1's l2: 0.107157\tvalid_1's RMSLE: 0.106589\n",
      "[580]\ttraining's l2: 0.088317\ttraining's RMSLE: 0.101143\tvalid_1's l2: 0.106502\tvalid_1's RMSLE: 0.106397\n",
      "[590]\ttraining's l2: 0.0875612\ttraining's RMSLE: 0.10073\tvalid_1's l2: 0.106002\tvalid_1's RMSLE: 0.106233\n",
      "[600]\ttraining's l2: 0.086812\ttraining's RMSLE: 0.100297\tvalid_1's l2: 0.105443\tvalid_1's RMSLE: 0.106055\n",
      "[610]\ttraining's l2: 0.0860249\ttraining's RMSLE: 0.0998953\tvalid_1's l2: 0.104776\tvalid_1's RMSLE: 0.10586\n",
      "[620]\ttraining's l2: 0.0853967\ttraining's RMSLE: 0.0995848\tvalid_1's l2: 0.104355\tvalid_1's RMSLE: 0.105733\n",
      "[630]\ttraining's l2: 0.0847751\ttraining's RMSLE: 0.0992213\tvalid_1's l2: 0.104013\tvalid_1's RMSLE: 0.105632\n",
      "[640]\ttraining's l2: 0.0841494\ttraining's RMSLE: 0.0989088\tvalid_1's l2: 0.103641\tvalid_1's RMSLE: 0.105534\n",
      "[650]\ttraining's l2: 0.0835546\ttraining's RMSLE: 0.0986101\tvalid_1's l2: 0.103223\tvalid_1's RMSLE: 0.105389\n",
      "[660]\ttraining's l2: 0.0829999\ttraining's RMSLE: 0.098292\tvalid_1's l2: 0.102927\tvalid_1's RMSLE: 0.10528\n",
      "[670]\ttraining's l2: 0.0824518\ttraining's RMSLE: 0.0980153\tvalid_1's l2: 0.102577\tvalid_1's RMSLE: 0.105184\n",
      "[680]\ttraining's l2: 0.0819202\ttraining's RMSLE: 0.0977372\tvalid_1's l2: 0.10226\tvalid_1's RMSLE: 0.105095\n",
      "[690]\ttraining's l2: 0.081249\ttraining's RMSLE: 0.0974181\tvalid_1's l2: 0.101697\tvalid_1's RMSLE: 0.104941\n",
      "[700]\ttraining's l2: 0.08068\ttraining's RMSLE: 0.0971452\tvalid_1's l2: 0.101268\tvalid_1's RMSLE: 0.104798\n",
      "[710]\ttraining's l2: 0.0801529\ttraining's RMSLE: 0.0969017\tvalid_1's l2: 0.100901\tvalid_1's RMSLE: 0.10469\n",
      "[720]\ttraining's l2: 0.0796257\ttraining's RMSLE: 0.0966034\tvalid_1's l2: 0.100593\tvalid_1's RMSLE: 0.104601\n",
      "[730]\ttraining's l2: 0.0791256\ttraining's RMSLE: 0.096335\tvalid_1's l2: 0.100339\tvalid_1's RMSLE: 0.104541\n",
      "[740]\ttraining's l2: 0.0786357\ttraining's RMSLE: 0.0960999\tvalid_1's l2: 0.100031\tvalid_1's RMSLE: 0.104448\n",
      "[750]\ttraining's l2: 0.0781445\ttraining's RMSLE: 0.0958544\tvalid_1's l2: 0.0997394\tvalid_1's RMSLE: 0.104384\n",
      "[760]\ttraining's l2: 0.0776931\ttraining's RMSLE: 0.0956433\tvalid_1's l2: 0.0994389\tvalid_1's RMSLE: 0.104333\n",
      "[770]\ttraining's l2: 0.0772196\ttraining's RMSLE: 0.0954103\tvalid_1's l2: 0.0991755\tvalid_1's RMSLE: 0.104289\n",
      "Early stopping, best iteration is:\n",
      "[768]\ttraining's l2: 0.0773083\ttraining's RMSLE: 0.0954667\tvalid_1's l2: 0.0991878\tvalid_1's RMSLE: 0.104272\n",
      "predict valid for fold 1\n",
      "save model for fold 1\n",
      "start training for fold 2\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 296\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 4.562794\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 1.86796\ttraining's RMSLE: 0.33765\tvalid_1's l2: 1.90091\tvalid_1's RMSLE: 0.344966\n",
      "[20]\ttraining's l2: 1.58769\ttraining's RMSLE: 0.318371\tvalid_1's l2: 1.61331\tvalid_1's RMSLE: 0.325349\n",
      "[30]\ttraining's l2: 1.35702\ttraining's RMSLE: 0.300666\tvalid_1's l2: 1.37717\tvalid_1's RMSLE: 0.30734\n",
      "[40]\ttraining's l2: 1.1668\ttraining's RMSLE: 0.284359\tvalid_1's l2: 1.18325\tvalid_1's RMSLE: 0.290844\n",
      "[50]\ttraining's l2: 1.00865\ttraining's RMSLE: 0.269365\tvalid_1's l2: 1.02238\tvalid_1's RMSLE: 0.275727\n",
      "[60]\ttraining's l2: 0.877711\ttraining's RMSLE: 0.255586\tvalid_1's l2: 0.888967\tvalid_1's RMSLE: 0.261808\n",
      "[70]\ttraining's l2: 0.76889\ttraining's RMSLE: 0.243094\tvalid_1's l2: 0.778816\tvalid_1's RMSLE: 0.249294\n",
      "[80]\ttraining's l2: 0.677848\ttraining's RMSLE: 0.231599\tvalid_1's l2: 0.687368\tvalid_1's RMSLE: 0.23788\n",
      "[90]\ttraining's l2: 0.601303\ttraining's RMSLE: 0.221141\tvalid_1's l2: 0.610871\tvalid_1's RMSLE: 0.227533\n",
      "[100]\ttraining's l2: 0.537745\ttraining's RMSLE: 0.211675\tvalid_1's l2: 0.547321\tvalid_1's RMSLE: 0.218202\n",
      "[110]\ttraining's l2: 0.484367\ttraining's RMSLE: 0.203102\tvalid_1's l2: 0.493916\tvalid_1's RMSLE: 0.209728\n",
      "[120]\ttraining's l2: 0.438093\ttraining's RMSLE: 0.19507\tvalid_1's l2: 0.447883\tvalid_1's RMSLE: 0.201881\n",
      "[130]\ttraining's l2: 0.398115\ttraining's RMSLE: 0.187537\tvalid_1's l2: 0.408071\tvalid_1's RMSLE: 0.194552\n",
      "[140]\ttraining's l2: 0.363162\ttraining's RMSLE: 0.180702\tvalid_1's l2: 0.37366\tvalid_1's RMSLE: 0.18794\n",
      "[150]\ttraining's l2: 0.332309\ttraining's RMSLE: 0.174353\tvalid_1's l2: 0.343151\tvalid_1's RMSLE: 0.181798\n",
      "[160]\ttraining's l2: 0.305562\ttraining's RMSLE: 0.168455\tvalid_1's l2: 0.317079\tvalid_1's RMSLE: 0.176192\n",
      "[170]\ttraining's l2: 0.281872\ttraining's RMSLE: 0.163032\tvalid_1's l2: 0.29411\tvalid_1's RMSLE: 0.17108\n",
      "[180]\ttraining's l2: 0.260657\ttraining's RMSLE: 0.158195\tvalid_1's l2: 0.273646\tvalid_1's RMSLE: 0.166538\n",
      "[190]\ttraining's l2: 0.24258\ttraining's RMSLE: 0.153798\tvalid_1's l2: 0.256288\tvalid_1's RMSLE: 0.162411\n",
      "[200]\ttraining's l2: 0.226725\ttraining's RMSLE: 0.149725\tvalid_1's l2: 0.241265\tvalid_1's RMSLE: 0.15864\n",
      "[210]\ttraining's l2: 0.212465\ttraining's RMSLE: 0.1459\tvalid_1's l2: 0.227851\tvalid_1's RMSLE: 0.155163\n",
      "[220]\ttraining's l2: 0.200085\ttraining's RMSLE: 0.14235\tvalid_1's l2: 0.216141\tvalid_1's RMSLE: 0.151918\n",
      "[230]\ttraining's l2: 0.188978\ttraining's RMSLE: 0.139172\tvalid_1's l2: 0.205572\tvalid_1's RMSLE: 0.148989\n",
      "[240]\ttraining's l2: 0.17946\ttraining's RMSLE: 0.136118\tvalid_1's l2: 0.196565\tvalid_1's RMSLE: 0.146257\n",
      "[250]\ttraining's l2: 0.170973\ttraining's RMSLE: 0.133297\tvalid_1's l2: 0.18857\tvalid_1's RMSLE: 0.14378\n",
      "[260]\ttraining's l2: 0.163111\ttraining's RMSLE: 0.13065\tvalid_1's l2: 0.18129\tvalid_1's RMSLE: 0.141508\n",
      "[270]\ttraining's l2: 0.156463\ttraining's RMSLE: 0.128181\tvalid_1's l2: 0.175189\tvalid_1's RMSLE: 0.139424\n",
      "[280]\ttraining's l2: 0.150233\ttraining's RMSLE: 0.125977\tvalid_1's l2: 0.169343\tvalid_1's RMSLE: 0.137533\n",
      "[290]\ttraining's l2: 0.144588\ttraining's RMSLE: 0.123952\tvalid_1's l2: 0.164067\tvalid_1's RMSLE: 0.135762\n",
      "[300]\ttraining's l2: 0.139445\ttraining's RMSLE: 0.122125\tvalid_1's l2: 0.159162\tvalid_1's RMSLE: 0.134174\n",
      "[310]\ttraining's l2: 0.134768\ttraining's RMSLE: 0.120478\tvalid_1's l2: 0.154768\tvalid_1's RMSLE: 0.132728\n",
      "[320]\ttraining's l2: 0.13071\ttraining's RMSLE: 0.118974\tvalid_1's l2: 0.151067\tvalid_1's RMSLE: 0.131434\n",
      "[330]\ttraining's l2: 0.126961\ttraining's RMSLE: 0.117562\tvalid_1's l2: 0.147659\tvalid_1's RMSLE: 0.130242\n",
      "[340]\ttraining's l2: 0.123602\ttraining's RMSLE: 0.116165\tvalid_1's l2: 0.144687\tvalid_1's RMSLE: 0.129103\n",
      "[350]\ttraining's l2: 0.120665\ttraining's RMSLE: 0.114839\tvalid_1's l2: 0.142122\tvalid_1's RMSLE: 0.128084\n",
      "[360]\ttraining's l2: 0.117932\ttraining's RMSLE: 0.113777\tvalid_1's l2: 0.1397\tvalid_1's RMSLE: 0.127219\n",
      "[370]\ttraining's l2: 0.115064\ttraining's RMSLE: 0.112701\tvalid_1's l2: 0.137087\tvalid_1's RMSLE: 0.126322\n",
      "[380]\ttraining's l2: 0.112579\ttraining's RMSLE: 0.11169\tvalid_1's l2: 0.134711\tvalid_1's RMSLE: 0.125457\n",
      "[390]\ttraining's l2: 0.11056\ttraining's RMSLE: 0.110689\tvalid_1's l2: 0.133011\tvalid_1's RMSLE: 0.12475\n",
      "[400]\ttraining's l2: 0.108632\ttraining's RMSLE: 0.109836\tvalid_1's l2: 0.131337\tvalid_1's RMSLE: 0.124093\n",
      "[410]\ttraining's l2: 0.106692\ttraining's RMSLE: 0.108914\tvalid_1's l2: 0.1296\tvalid_1's RMSLE: 0.123375\n",
      "[420]\ttraining's l2: 0.104941\ttraining's RMSLE: 0.108107\tvalid_1's l2: 0.128147\tvalid_1's RMSLE: 0.122789\n",
      "[430]\ttraining's l2: 0.103279\ttraining's RMSLE: 0.107378\tvalid_1's l2: 0.126687\tvalid_1's RMSLE: 0.12224\n",
      "[440]\ttraining's l2: 0.101531\ttraining's RMSLE: 0.106624\tvalid_1's l2: 0.125152\tvalid_1's RMSLE: 0.121644\n",
      "[450]\ttraining's l2: 0.100104\ttraining's RMSLE: 0.106017\tvalid_1's l2: 0.12393\tvalid_1's RMSLE: 0.121171\n",
      "[460]\ttraining's l2: 0.0988166\ttraining's RMSLE: 0.105346\tvalid_1's l2: 0.122841\tvalid_1's RMSLE: 0.12069\n",
      "[470]\ttraining's l2: 0.0974611\ttraining's RMSLE: 0.104673\tvalid_1's l2: 0.121665\tvalid_1's RMSLE: 0.120234\n",
      "[480]\ttraining's l2: 0.0961957\ttraining's RMSLE: 0.104018\tvalid_1's l2: 0.120627\tvalid_1's RMSLE: 0.11984\n",
      "[490]\ttraining's l2: 0.0950708\ttraining's RMSLE: 0.103439\tvalid_1's l2: 0.119676\tvalid_1's RMSLE: 0.119486\n",
      "[500]\ttraining's l2: 0.0940521\ttraining's RMSLE: 0.102914\tvalid_1's l2: 0.118887\tvalid_1's RMSLE: 0.119167\n",
      "[510]\ttraining's l2: 0.0930554\ttraining's RMSLE: 0.102428\tvalid_1's l2: 0.118026\tvalid_1's RMSLE: 0.118825\n",
      "[520]\ttraining's l2: 0.0920139\ttraining's RMSLE: 0.101898\tvalid_1's l2: 0.117234\tvalid_1's RMSLE: 0.118495\n",
      "[530]\ttraining's l2: 0.0910495\ttraining's RMSLE: 0.101436\tvalid_1's l2: 0.116498\tvalid_1's RMSLE: 0.118193\n",
      "[540]\ttraining's l2: 0.0900736\ttraining's RMSLE: 0.100963\tvalid_1's l2: 0.115781\tvalid_1's RMSLE: 0.117925\n",
      "[550]\ttraining's l2: 0.0889636\ttraining's RMSLE: 0.100475\tvalid_1's l2: 0.114857\tvalid_1's RMSLE: 0.117625\n",
      "[560]\ttraining's l2: 0.0879587\ttraining's RMSLE: 0.100017\tvalid_1's l2: 0.114002\tvalid_1's RMSLE: 0.117343\n",
      "[570]\ttraining's l2: 0.0870458\ttraining's RMSLE: 0.0996088\tvalid_1's l2: 0.113276\tvalid_1's RMSLE: 0.117092\n",
      "[580]\ttraining's l2: 0.0861265\ttraining's RMSLE: 0.0991751\tvalid_1's l2: 0.112493\tvalid_1's RMSLE: 0.116795\n",
      "[590]\ttraining's l2: 0.0853609\ttraining's RMSLE: 0.0988354\tvalid_1's l2: 0.111889\tvalid_1's RMSLE: 0.116544\n",
      "[600]\ttraining's l2: 0.0846423\ttraining's RMSLE: 0.0984993\tvalid_1's l2: 0.111345\tvalid_1's RMSLE: 0.116333\n",
      "[610]\ttraining's l2: 0.0839358\ttraining's RMSLE: 0.0982015\tvalid_1's l2: 0.110781\tvalid_1's RMSLE: 0.116123\n",
      "[620]\ttraining's l2: 0.0832039\ttraining's RMSLE: 0.097857\tvalid_1's l2: 0.11023\tvalid_1's RMSLE: 0.115897\n",
      "[630]\ttraining's l2: 0.0825591\ttraining's RMSLE: 0.0975395\tvalid_1's l2: 0.109776\tvalid_1's RMSLE: 0.115692\n",
      "[640]\ttraining's l2: 0.0819379\ttraining's RMSLE: 0.0972501\tvalid_1's l2: 0.109276\tvalid_1's RMSLE: 0.115488\n",
      "[650]\ttraining's l2: 0.0812914\ttraining's RMSLE: 0.0969371\tvalid_1's l2: 0.108824\tvalid_1's RMSLE: 0.115301\n",
      "[660]\ttraining's l2: 0.0807577\ttraining's RMSLE: 0.0966809\tvalid_1's l2: 0.108484\tvalid_1's RMSLE: 0.115179\n",
      "[670]\ttraining's l2: 0.0801799\ttraining's RMSLE: 0.0964036\tvalid_1's l2: 0.108082\tvalid_1's RMSLE: 0.115033\n",
      "[680]\ttraining's l2: 0.0796461\ttraining's RMSLE: 0.0961486\tvalid_1's l2: 0.107728\tvalid_1's RMSLE: 0.114916\n",
      "[690]\ttraining's l2: 0.0791047\ttraining's RMSLE: 0.0958757\tvalid_1's l2: 0.10741\tvalid_1's RMSLE: 0.114796\n",
      "[700]\ttraining's l2: 0.0785448\ttraining's RMSLE: 0.0955995\tvalid_1's l2: 0.107114\tvalid_1's RMSLE: 0.114687\n",
      "[710]\ttraining's l2: 0.0779972\ttraining's RMSLE: 0.0953451\tvalid_1's l2: 0.106743\tvalid_1's RMSLE: 0.114544\n",
      "[720]\ttraining's l2: 0.0773377\ttraining's RMSLE: 0.0950426\tvalid_1's l2: 0.106257\tvalid_1's RMSLE: 0.114362\n",
      "[730]\ttraining's l2: 0.0768561\ttraining's RMSLE: 0.0948423\tvalid_1's l2: 0.105964\tvalid_1's RMSLE: 0.114277\n",
      "[740]\ttraining's l2: 0.0763226\ttraining's RMSLE: 0.0946067\tvalid_1's l2: 0.105565\tvalid_1's RMSLE: 0.114135\n",
      "[750]\ttraining's l2: 0.0758821\ttraining's RMSLE: 0.0943773\tvalid_1's l2: 0.105294\tvalid_1's RMSLE: 0.114042\n",
      "[760]\ttraining's l2: 0.0754038\ttraining's RMSLE: 0.0941388\tvalid_1's l2: 0.104962\tvalid_1's RMSLE: 0.113943\n",
      "[770]\ttraining's l2: 0.0749844\ttraining's RMSLE: 0.0939197\tvalid_1's l2: 0.104756\tvalid_1's RMSLE: 0.113883\n",
      "[780]\ttraining's l2: 0.0745884\ttraining's RMSLE: 0.0937111\tvalid_1's l2: 0.104556\tvalid_1's RMSLE: 0.11382\n",
      "[790]\ttraining's l2: 0.0741038\ttraining's RMSLE: 0.0934848\tvalid_1's l2: 0.104283\tvalid_1's RMSLE: 0.11374\n",
      "[800]\ttraining's l2: 0.0736807\ttraining's RMSLE: 0.0932923\tvalid_1's l2: 0.104063\tvalid_1's RMSLE: 0.113676\n",
      "[810]\ttraining's l2: 0.0732627\ttraining's RMSLE: 0.0930872\tvalid_1's l2: 0.103831\tvalid_1's RMSLE: 0.113612\n",
      "[820]\ttraining's l2: 0.0729133\ttraining's RMSLE: 0.0928846\tvalid_1's l2: 0.103676\tvalid_1's RMSLE: 0.113563\n",
      "[830]\ttraining's l2: 0.0725643\ttraining's RMSLE: 0.0927144\tvalid_1's l2: 0.103513\tvalid_1's RMSLE: 0.113513\n",
      "[840]\ttraining's l2: 0.0721731\ttraining's RMSLE: 0.092478\tvalid_1's l2: 0.10334\tvalid_1's RMSLE: 0.113489\n",
      "[850]\ttraining's l2: 0.0718371\ttraining's RMSLE: 0.0922916\tvalid_1's l2: 0.10318\tvalid_1's RMSLE: 0.113433\n",
      "[860]\ttraining's l2: 0.0714419\ttraining's RMSLE: 0.09207\tvalid_1's l2: 0.102971\tvalid_1's RMSLE: 0.11337\n",
      "[870]\ttraining's l2: 0.071115\ttraining's RMSLE: 0.0918719\tvalid_1's l2: 0.102862\tvalid_1's RMSLE: 0.113334\n",
      "[880]\ttraining's l2: 0.0708099\ttraining's RMSLE: 0.091709\tvalid_1's l2: 0.102698\tvalid_1's RMSLE: 0.113266\n",
      "[890]\ttraining's l2: 0.0705388\ttraining's RMSLE: 0.0915615\tvalid_1's l2: 0.102583\tvalid_1's RMSLE: 0.113199\n",
      "[900]\ttraining's l2: 0.0702768\ttraining's RMSLE: 0.0914122\tvalid_1's l2: 0.102503\tvalid_1's RMSLE: 0.113157\n",
      "[910]\ttraining's l2: 0.0699699\ttraining's RMSLE: 0.0912353\tvalid_1's l2: 0.102416\tvalid_1's RMSLE: 0.113116\n",
      "[920]\ttraining's l2: 0.069709\ttraining's RMSLE: 0.091072\tvalid_1's l2: 0.102323\tvalid_1's RMSLE: 0.113093\n",
      "[930]\ttraining's l2: 0.0694718\ttraining's RMSLE: 0.090921\tvalid_1's l2: 0.102265\tvalid_1's RMSLE: 0.113065\n",
      "[940]\ttraining's l2: 0.0692107\ttraining's RMSLE: 0.0907714\tvalid_1's l2: 0.102205\tvalid_1's RMSLE: 0.113051\n",
      "[950]\ttraining's l2: 0.0689275\ttraining's RMSLE: 0.0906077\tvalid_1's l2: 0.102114\tvalid_1's RMSLE: 0.113027\n",
      "[960]\ttraining's l2: 0.0686572\ttraining's RMSLE: 0.0904438\tvalid_1's l2: 0.10203\tvalid_1's RMSLE: 0.113008\n",
      "[970]\ttraining's l2: 0.0683783\ttraining's RMSLE: 0.0902832\tvalid_1's l2: 0.101901\tvalid_1's RMSLE: 0.112956\n",
      "[980]\ttraining's l2: 0.0681338\ttraining's RMSLE: 0.0901512\tvalid_1's l2: 0.101797\tvalid_1's RMSLE: 0.112914\n",
      "[990]\ttraining's l2: 0.0678668\ttraining's RMSLE: 0.0900007\tvalid_1's l2: 0.101694\tvalid_1's RMSLE: 0.112865\n",
      "[1000]\ttraining's l2: 0.0676214\ttraining's RMSLE: 0.08989\tvalid_1's l2: 0.101587\tvalid_1's RMSLE: 0.112844\n",
      "[1010]\ttraining's l2: 0.0673637\ttraining's RMSLE: 0.0897405\tvalid_1's l2: 0.101489\tvalid_1's RMSLE: 0.112796\n",
      "[1020]\ttraining's l2: 0.0670951\ttraining's RMSLE: 0.0895986\tvalid_1's l2: 0.101381\tvalid_1's RMSLE: 0.112771\n",
      "[1030]\ttraining's l2: 0.066837\ttraining's RMSLE: 0.0894565\tvalid_1's l2: 0.101276\tvalid_1's RMSLE: 0.112754\n",
      "[1040]\ttraining's l2: 0.066614\ttraining's RMSLE: 0.0893517\tvalid_1's l2: 0.101203\tvalid_1's RMSLE: 0.112729\n",
      "[1050]\ttraining's l2: 0.0663594\ttraining's RMSLE: 0.0892222\tvalid_1's l2: 0.101114\tvalid_1's RMSLE: 0.112711\n",
      "[1060]\ttraining's l2: 0.0660947\ttraining's RMSLE: 0.0890796\tvalid_1's l2: 0.101016\tvalid_1's RMSLE: 0.112672\n",
      "[1070]\ttraining's l2: 0.0657985\ttraining's RMSLE: 0.0888803\tvalid_1's l2: 0.100907\tvalid_1's RMSLE: 0.112611\n",
      "[1080]\ttraining's l2: 0.0655931\ttraining's RMSLE: 0.088775\tvalid_1's l2: 0.100864\tvalid_1's RMSLE: 0.112586\n",
      "[1090]\ttraining's l2: 0.0653902\ttraining's RMSLE: 0.0886807\tvalid_1's l2: 0.100812\tvalid_1's RMSLE: 0.112568\n",
      "[1100]\ttraining's l2: 0.0651068\ttraining's RMSLE: 0.0885212\tvalid_1's l2: 0.100682\tvalid_1's RMSLE: 0.1125\n",
      "[1110]\ttraining's l2: 0.0648661\ttraining's RMSLE: 0.0883958\tvalid_1's l2: 0.100608\tvalid_1's RMSLE: 0.112469\n",
      "[1120]\ttraining's l2: 0.0646253\ttraining's RMSLE: 0.0882855\tvalid_1's l2: 0.100543\tvalid_1's RMSLE: 0.112448\n",
      "[1130]\ttraining's l2: 0.0643339\ttraining's RMSLE: 0.088094\tvalid_1's l2: 0.100458\tvalid_1's RMSLE: 0.112406\n",
      "[1140]\ttraining's l2: 0.063936\ttraining's RMSLE: 0.0878472\tvalid_1's l2: 0.100234\tvalid_1's RMSLE: 0.112332\n",
      "[1150]\ttraining's l2: 0.0636744\ttraining's RMSLE: 0.0877006\tvalid_1's l2: 0.100135\tvalid_1's RMSLE: 0.112285\n",
      "[1160]\ttraining's l2: 0.0634564\ttraining's RMSLE: 0.0875873\tvalid_1's l2: 0.100063\tvalid_1's RMSLE: 0.112267\n",
      "[1170]\ttraining's l2: 0.0631972\ttraining's RMSLE: 0.0874409\tvalid_1's l2: 0.0999017\tvalid_1's RMSLE: 0.112216\n",
      "[1180]\ttraining's l2: 0.0629701\ttraining's RMSLE: 0.0873132\tvalid_1's l2: 0.0998194\tvalid_1's RMSLE: 0.112199\n",
      "[1190]\ttraining's l2: 0.0626988\ttraining's RMSLE: 0.0871634\tvalid_1's l2: 0.0996824\tvalid_1's RMSLE: 0.112154\n",
      "[1200]\ttraining's l2: 0.0625017\ttraining's RMSLE: 0.0870641\tvalid_1's l2: 0.0996223\tvalid_1's RMSLE: 0.112146\n",
      "[1210]\ttraining's l2: 0.0622465\ttraining's RMSLE: 0.0869124\tvalid_1's l2: 0.0995524\tvalid_1's RMSLE: 0.112136\n",
      "[1220]\ttraining's l2: 0.0620438\ttraining's RMSLE: 0.0868032\tvalid_1's l2: 0.0994838\tvalid_1's RMSLE: 0.112121\n",
      "[1230]\ttraining's l2: 0.0618319\ttraining's RMSLE: 0.0866867\tvalid_1's l2: 0.0994217\tvalid_1's RMSLE: 0.112102\n",
      "[1240]\ttraining's l2: 0.0616038\ttraining's RMSLE: 0.0865349\tvalid_1's l2: 0.0993615\tvalid_1's RMSLE: 0.11208\n",
      "[1250]\ttraining's l2: 0.0614065\ttraining's RMSLE: 0.0864158\tvalid_1's l2: 0.0993159\tvalid_1's RMSLE: 0.112079\n",
      "[1260]\ttraining's l2: 0.061219\ttraining's RMSLE: 0.0862969\tvalid_1's l2: 0.0992633\tvalid_1's RMSLE: 0.112068\n",
      "[1270]\ttraining's l2: 0.0609847\ttraining's RMSLE: 0.0861549\tvalid_1's l2: 0.0991789\tvalid_1's RMSLE: 0.112038\n",
      "[1280]\ttraining's l2: 0.0607453\ttraining's RMSLE: 0.0860077\tvalid_1's l2: 0.099085\tvalid_1's RMSLE: 0.112011\n",
      "[1290]\ttraining's l2: 0.0605291\ttraining's RMSLE: 0.0858693\tvalid_1's l2: 0.0990238\tvalid_1's RMSLE: 0.111999\n",
      "[1300]\ttraining's l2: 0.060313\ttraining's RMSLE: 0.0857334\tvalid_1's l2: 0.098957\tvalid_1's RMSLE: 0.111981\n",
      "[1310]\ttraining's l2: 0.0601225\ttraining's RMSLE: 0.0856196\tvalid_1's l2: 0.0989063\tvalid_1's RMSLE: 0.111964\n",
      "[1320]\ttraining's l2: 0.0599171\ttraining's RMSLE: 0.0854837\tvalid_1's l2: 0.0988433\tvalid_1's RMSLE: 0.111949\n",
      "[1330]\ttraining's l2: 0.0597564\ttraining's RMSLE: 0.085395\tvalid_1's l2: 0.0988169\tvalid_1's RMSLE: 0.111948\n",
      "Early stopping, best iteration is:\n",
      "[1329]\ttraining's l2: 0.0597724\ttraining's RMSLE: 0.0854054\tvalid_1's l2: 0.0988103\tvalid_1's RMSLE: 0.111945\n",
      "predict valid for fold 2\n",
      "save model for fold 2\n",
      "start training for fold 3\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 296\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 4.532793\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 1.90102\ttraining's RMSLE: 0.342568\tvalid_1's l2: 1.77858\tvalid_1's RMSLE: 0.321277\n",
      "[20]\ttraining's l2: 1.61616\ttraining's RMSLE: 0.323073\tvalid_1's l2: 1.5186\tvalid_1's RMSLE: 0.303061\n",
      "[30]\ttraining's l2: 1.38099\ttraining's RMSLE: 0.305085\tvalid_1's l2: 1.30331\tvalid_1's RMSLE: 0.286283\n",
      "[40]\ttraining's l2: 1.1872\ttraining's RMSLE: 0.288554\tvalid_1's l2: 1.12556\tvalid_1's RMSLE: 0.270929\n",
      "[50]\ttraining's l2: 1.02562\ttraining's RMSLE: 0.273301\tvalid_1's l2: 0.977439\tvalid_1's RMSLE: 0.256849\n",
      "[60]\ttraining's l2: 0.891853\ttraining's RMSLE: 0.259371\tvalid_1's l2: 0.853668\tvalid_1's RMSLE: 0.243969\n",
      "[70]\ttraining's l2: 0.779509\ttraining's RMSLE: 0.246466\tvalid_1's l2: 0.749884\tvalid_1's RMSLE: 0.232128\n",
      "[80]\ttraining's l2: 0.68645\ttraining's RMSLE: 0.234931\tvalid_1's l2: 0.663662\tvalid_1's RMSLE: 0.221595\n",
      "[90]\ttraining's l2: 0.608455\ttraining's RMSLE: 0.22438\tvalid_1's l2: 0.591398\tvalid_1's RMSLE: 0.211999\n",
      "[100]\ttraining's l2: 0.543825\ttraining's RMSLE: 0.214875\tvalid_1's l2: 0.531372\tvalid_1's RMSLE: 0.20339\n",
      "[110]\ttraining's l2: 0.488261\ttraining's RMSLE: 0.206004\tvalid_1's l2: 0.480371\tvalid_1's RMSLE: 0.19547\n",
      "[120]\ttraining's l2: 0.440506\ttraining's RMSLE: 0.1977\tvalid_1's l2: 0.436453\tvalid_1's RMSLE: 0.188084\n",
      "[130]\ttraining's l2: 0.399849\ttraining's RMSLE: 0.190154\tvalid_1's l2: 0.398998\tvalid_1's RMSLE: 0.181389\n",
      "[140]\ttraining's l2: 0.363903\ttraining's RMSLE: 0.183046\tvalid_1's l2: 0.365841\tvalid_1's RMSLE: 0.175104\n",
      "[150]\ttraining's l2: 0.334416\ttraining's RMSLE: 0.176675\tvalid_1's l2: 0.338454\tvalid_1's RMSLE: 0.169489\n",
      "[160]\ttraining's l2: 0.308321\ttraining's RMSLE: 0.170885\tvalid_1's l2: 0.314149\tvalid_1's RMSLE: 0.164401\n",
      "[170]\ttraining's l2: 0.28395\ttraining's RMSLE: 0.165291\tvalid_1's l2: 0.291289\tvalid_1's RMSLE: 0.159473\n",
      "[180]\ttraining's l2: 0.261842\ttraining's RMSLE: 0.160363\tvalid_1's l2: 0.2703\tvalid_1's RMSLE: 0.155137\n",
      "[190]\ttraining's l2: 0.242847\ttraining's RMSLE: 0.155879\tvalid_1's l2: 0.252027\tvalid_1's RMSLE: 0.151183\n",
      "[200]\ttraining's l2: 0.227197\ttraining's RMSLE: 0.151753\tvalid_1's l2: 0.237086\tvalid_1's RMSLE: 0.147587\n",
      "[210]\ttraining's l2: 0.213318\ttraining's RMSLE: 0.148023\tvalid_1's l2: 0.223912\tvalid_1's RMSLE: 0.144368\n",
      "[220]\ttraining's l2: 0.201155\ttraining's RMSLE: 0.144387\tvalid_1's l2: 0.212531\tvalid_1's RMSLE: 0.141282\n",
      "[230]\ttraining's l2: 0.190547\ttraining's RMSLE: 0.141058\tvalid_1's l2: 0.20257\tvalid_1's RMSLE: 0.138423\n",
      "[240]\ttraining's l2: 0.181387\ttraining's RMSLE: 0.138077\tvalid_1's l2: 0.19373\tvalid_1's RMSLE: 0.135858\n",
      "[250]\ttraining's l2: 0.172704\ttraining's RMSLE: 0.135319\tvalid_1's l2: 0.185201\tvalid_1's RMSLE: 0.133438\n",
      "[260]\ttraining's l2: 0.165102\ttraining's RMSLE: 0.132856\tvalid_1's l2: 0.177634\tvalid_1's RMSLE: 0.131274\n",
      "[270]\ttraining's l2: 0.158069\ttraining's RMSLE: 0.130438\tvalid_1's l2: 0.170679\tvalid_1's RMSLE: 0.129138\n",
      "[280]\ttraining's l2: 0.151675\ttraining's RMSLE: 0.128304\tvalid_1's l2: 0.164282\tvalid_1's RMSLE: 0.127259\n",
      "[290]\ttraining's l2: 0.146196\ttraining's RMSLE: 0.126375\tvalid_1's l2: 0.158862\tvalid_1's RMSLE: 0.125584\n",
      "[300]\ttraining's l2: 0.141152\ttraining's RMSLE: 0.12456\tvalid_1's l2: 0.153871\tvalid_1's RMSLE: 0.124019\n",
      "[310]\ttraining's l2: 0.136459\ttraining's RMSLE: 0.122803\tvalid_1's l2: 0.149368\tvalid_1's RMSLE: 0.12254\n",
      "[320]\ttraining's l2: 0.132306\ttraining's RMSLE: 0.121294\tvalid_1's l2: 0.145283\tvalid_1's RMSLE: 0.121241\n",
      "[330]\ttraining's l2: 0.128503\ttraining's RMSLE: 0.119902\tvalid_1's l2: 0.141597\tvalid_1's RMSLE: 0.120044\n",
      "[340]\ttraining's l2: 0.125307\ttraining's RMSLE: 0.118629\tvalid_1's l2: 0.138499\tvalid_1's RMSLE: 0.118935\n",
      "[350]\ttraining's l2: 0.122151\ttraining's RMSLE: 0.117362\tvalid_1's l2: 0.1355\tvalid_1's RMSLE: 0.117874\n",
      "[360]\ttraining's l2: 0.119521\ttraining's RMSLE: 0.116222\tvalid_1's l2: 0.133027\tvalid_1's RMSLE: 0.116916\n",
      "[370]\ttraining's l2: 0.116885\ttraining's RMSLE: 0.115137\tvalid_1's l2: 0.130583\tvalid_1's RMSLE: 0.116039\n",
      "[380]\ttraining's l2: 0.114548\ttraining's RMSLE: 0.113929\tvalid_1's l2: 0.128557\tvalid_1's RMSLE: 0.115123\n",
      "[390]\ttraining's l2: 0.112191\ttraining's RMSLE: 0.112816\tvalid_1's l2: 0.126465\tvalid_1's RMSLE: 0.114289\n",
      "[400]\ttraining's l2: 0.110209\ttraining's RMSLE: 0.111949\tvalid_1's l2: 0.124731\tvalid_1's RMSLE: 0.113625\n",
      "[410]\ttraining's l2: 0.108194\ttraining's RMSLE: 0.111118\tvalid_1's l2: 0.122837\tvalid_1's RMSLE: 0.112997\n",
      "[420]\ttraining's l2: 0.106309\ttraining's RMSLE: 0.110303\tvalid_1's l2: 0.121171\tvalid_1's RMSLE: 0.112416\n",
      "[430]\ttraining's l2: 0.104615\ttraining's RMSLE: 0.109558\tvalid_1's l2: 0.119704\tvalid_1's RMSLE: 0.111879\n",
      "[440]\ttraining's l2: 0.103093\ttraining's RMSLE: 0.108837\tvalid_1's l2: 0.118295\tvalid_1's RMSLE: 0.111301\n",
      "[450]\ttraining's l2: 0.101579\ttraining's RMSLE: 0.108129\tvalid_1's l2: 0.116923\tvalid_1's RMSLE: 0.110736\n",
      "[460]\ttraining's l2: 0.100207\ttraining's RMSLE: 0.107521\tvalid_1's l2: 0.115741\tvalid_1's RMSLE: 0.110296\n",
      "[470]\ttraining's l2: 0.0990281\ttraining's RMSLE: 0.106947\tvalid_1's l2: 0.114837\tvalid_1's RMSLE: 0.109924\n",
      "[480]\ttraining's l2: 0.0979271\ttraining's RMSLE: 0.106436\tvalid_1's l2: 0.114013\tvalid_1's RMSLE: 0.109631\n",
      "[490]\ttraining's l2: 0.0968536\ttraining's RMSLE: 0.105956\tvalid_1's l2: 0.113215\tvalid_1's RMSLE: 0.109356\n",
      "[500]\ttraining's l2: 0.0957489\ttraining's RMSLE: 0.105466\tvalid_1's l2: 0.112395\tvalid_1's RMSLE: 0.109084\n",
      "[510]\ttraining's l2: 0.0946132\ttraining's RMSLE: 0.104944\tvalid_1's l2: 0.111531\tvalid_1's RMSLE: 0.108792\n",
      "[520]\ttraining's l2: 0.0935769\ttraining's RMSLE: 0.104481\tvalid_1's l2: 0.11071\tvalid_1's RMSLE: 0.108517\n",
      "[530]\ttraining's l2: 0.0926197\ttraining's RMSLE: 0.103985\tvalid_1's l2: 0.110037\tvalid_1's RMSLE: 0.10823\n",
      "[540]\ttraining's l2: 0.0916955\ttraining's RMSLE: 0.103525\tvalid_1's l2: 0.109436\tvalid_1's RMSLE: 0.108\n",
      "[550]\ttraining's l2: 0.0907989\ttraining's RMSLE: 0.103074\tvalid_1's l2: 0.108794\tvalid_1's RMSLE: 0.107745\n",
      "[560]\ttraining's l2: 0.0899509\ttraining's RMSLE: 0.102648\tvalid_1's l2: 0.108172\tvalid_1's RMSLE: 0.107481\n",
      "[570]\ttraining's l2: 0.0890699\ttraining's RMSLE: 0.102212\tvalid_1's l2: 0.107516\tvalid_1's RMSLE: 0.107222\n",
      "[580]\ttraining's l2: 0.0882807\ttraining's RMSLE: 0.101827\tvalid_1's l2: 0.106924\tvalid_1's RMSLE: 0.107028\n",
      "[590]\ttraining's l2: 0.0873231\ttraining's RMSLE: 0.101382\tvalid_1's l2: 0.106188\tvalid_1's RMSLE: 0.106789\n",
      "[600]\ttraining's l2: 0.0863914\ttraining's RMSLE: 0.100896\tvalid_1's l2: 0.105461\tvalid_1's RMSLE: 0.106535\n",
      "[610]\ttraining's l2: 0.085571\ttraining's RMSLE: 0.100435\tvalid_1's l2: 0.104854\tvalid_1's RMSLE: 0.106254\n",
      "[620]\ttraining's l2: 0.0848728\ttraining's RMSLE: 0.100086\tvalid_1's l2: 0.104371\tvalid_1's RMSLE: 0.106036\n",
      "[630]\ttraining's l2: 0.0841879\ttraining's RMSLE: 0.0997136\tvalid_1's l2: 0.10389\tvalid_1's RMSLE: 0.105817\n",
      "[640]\ttraining's l2: 0.083562\ttraining's RMSLE: 0.0993982\tvalid_1's l2: 0.103483\tvalid_1's RMSLE: 0.105669\n",
      "[650]\ttraining's l2: 0.0829204\ttraining's RMSLE: 0.0990561\tvalid_1's l2: 0.103085\tvalid_1's RMSLE: 0.105498\n",
      "[660]\ttraining's l2: 0.0822814\ttraining's RMSLE: 0.0987156\tvalid_1's l2: 0.102669\tvalid_1's RMSLE: 0.105316\n",
      "[670]\ttraining's l2: 0.0817051\ttraining's RMSLE: 0.0984161\tvalid_1's l2: 0.102353\tvalid_1's RMSLE: 0.105182\n",
      "[680]\ttraining's l2: 0.0810982\ttraining's RMSLE: 0.0980602\tvalid_1's l2: 0.102047\tvalid_1's RMSLE: 0.10503\n",
      "[690]\ttraining's l2: 0.0805089\ttraining's RMSLE: 0.0977457\tvalid_1's l2: 0.101683\tvalid_1's RMSLE: 0.104866\n",
      "[700]\ttraining's l2: 0.0799756\ttraining's RMSLE: 0.0974623\tvalid_1's l2: 0.101446\tvalid_1's RMSLE: 0.104782\n",
      "[710]\ttraining's l2: 0.0794468\ttraining's RMSLE: 0.0971706\tvalid_1's l2: 0.10111\tvalid_1's RMSLE: 0.104626\n",
      "[720]\ttraining's l2: 0.0789248\ttraining's RMSLE: 0.0968976\tvalid_1's l2: 0.100792\tvalid_1's RMSLE: 0.104502\n",
      "[730]\ttraining's l2: 0.0784598\ttraining's RMSLE: 0.096672\tvalid_1's l2: 0.100589\tvalid_1's RMSLE: 0.104475\n",
      "[740]\ttraining's l2: 0.0779524\ttraining's RMSLE: 0.0964464\tvalid_1's l2: 0.100253\tvalid_1's RMSLE: 0.104374\n",
      "[750]\ttraining's l2: 0.0774731\ttraining's RMSLE: 0.0962494\tvalid_1's l2: 0.0999869\tvalid_1's RMSLE: 0.104298\n",
      "[760]\ttraining's l2: 0.0770294\ttraining's RMSLE: 0.0960561\tvalid_1's l2: 0.0997543\tvalid_1's RMSLE: 0.104232\n",
      "[770]\ttraining's l2: 0.0765858\ttraining's RMSLE: 0.0958559\tvalid_1's l2: 0.0994788\tvalid_1's RMSLE: 0.104161\n",
      "[780]\ttraining's l2: 0.0761558\ttraining's RMSLE: 0.0956392\tvalid_1's l2: 0.0992506\tvalid_1's RMSLE: 0.104095\n",
      "[790]\ttraining's l2: 0.0757165\ttraining's RMSLE: 0.0954234\tvalid_1's l2: 0.0989954\tvalid_1's RMSLE: 0.104025\n",
      "[800]\ttraining's l2: 0.0752523\ttraining's RMSLE: 0.0951705\tvalid_1's l2: 0.0988331\tvalid_1's RMSLE: 0.103964\n",
      "[810]\ttraining's l2: 0.0747973\ttraining's RMSLE: 0.0949437\tvalid_1's l2: 0.0985926\tvalid_1's RMSLE: 0.103897\n",
      "[820]\ttraining's l2: 0.0743569\ttraining's RMSLE: 0.0947051\tvalid_1's l2: 0.0983632\tvalid_1's RMSLE: 0.103811\n",
      "[830]\ttraining's l2: 0.0739966\ttraining's RMSLE: 0.0945374\tvalid_1's l2: 0.0981351\tvalid_1's RMSLE: 0.103768\n",
      "[840]\ttraining's l2: 0.0736499\ttraining's RMSLE: 0.0943521\tvalid_1's l2: 0.0979697\tvalid_1's RMSLE: 0.10373\n",
      "[850]\ttraining's l2: 0.0733079\ttraining's RMSLE: 0.0941768\tvalid_1's l2: 0.0977588\tvalid_1's RMSLE: 0.103641\n",
      "[860]\ttraining's l2: 0.0729535\ttraining's RMSLE: 0.0939951\tvalid_1's l2: 0.0976423\tvalid_1's RMSLE: 0.103614\n",
      "[870]\ttraining's l2: 0.0726043\ttraining's RMSLE: 0.0938423\tvalid_1's l2: 0.0974744\tvalid_1's RMSLE: 0.10357\n",
      "[880]\ttraining's l2: 0.0722716\ttraining's RMSLE: 0.0936714\tvalid_1's l2: 0.0973064\tvalid_1's RMSLE: 0.10353\n",
      "[890]\ttraining's l2: 0.0719623\ttraining's RMSLE: 0.0935245\tvalid_1's l2: 0.0971633\tvalid_1's RMSLE: 0.103487\n",
      "[900]\ttraining's l2: 0.0716771\ttraining's RMSLE: 0.0933971\tvalid_1's l2: 0.097032\tvalid_1's RMSLE: 0.103449\n",
      "[910]\ttraining's l2: 0.0713372\ttraining's RMSLE: 0.0932344\tvalid_1's l2: 0.096905\tvalid_1's RMSLE: 0.103411\n",
      "[920]\ttraining's l2: 0.0710554\ttraining's RMSLE: 0.0930707\tvalid_1's l2: 0.0967988\tvalid_1's RMSLE: 0.103384\n",
      "[930]\ttraining's l2: 0.0707911\ttraining's RMSLE: 0.0929348\tvalid_1's l2: 0.0967001\tvalid_1's RMSLE: 0.103353\n",
      "[940]\ttraining's l2: 0.0705157\ttraining's RMSLE: 0.0927675\tvalid_1's l2: 0.0965865\tvalid_1's RMSLE: 0.103309\n",
      "[950]\ttraining's l2: 0.0702127\ttraining's RMSLE: 0.0925959\tvalid_1's l2: 0.0964733\tvalid_1's RMSLE: 0.103265\n",
      "[960]\ttraining's l2: 0.0699358\ttraining's RMSLE: 0.0924353\tvalid_1's l2: 0.0963914\tvalid_1's RMSLE: 0.103224\n",
      "[970]\ttraining's l2: 0.069691\ttraining's RMSLE: 0.0923126\tvalid_1's l2: 0.0962573\tvalid_1's RMSLE: 0.103178\n",
      "[980]\ttraining's l2: 0.0694301\ttraining's RMSLE: 0.0921669\tvalid_1's l2: 0.0961474\tvalid_1's RMSLE: 0.103139\n",
      "[990]\ttraining's l2: 0.0691823\ttraining's RMSLE: 0.0920452\tvalid_1's l2: 0.0960149\tvalid_1's RMSLE: 0.10311\n",
      "[1000]\ttraining's l2: 0.0689131\ttraining's RMSLE: 0.0919102\tvalid_1's l2: 0.0958861\tvalid_1's RMSLE: 0.103073\n",
      "[1010]\ttraining's l2: 0.0686604\ttraining's RMSLE: 0.091749\tvalid_1's l2: 0.0958079\tvalid_1's RMSLE: 0.103042\n",
      "[1020]\ttraining's l2: 0.0683614\ttraining's RMSLE: 0.0915772\tvalid_1's l2: 0.0956974\tvalid_1's RMSLE: 0.103002\n",
      "[1030]\ttraining's l2: 0.0681126\ttraining's RMSLE: 0.0914525\tvalid_1's l2: 0.0955853\tvalid_1's RMSLE: 0.102994\n",
      "[1040]\ttraining's l2: 0.067871\ttraining's RMSLE: 0.0913189\tvalid_1's l2: 0.0954893\tvalid_1's RMSLE: 0.102955\n",
      "[1050]\ttraining's l2: 0.0676413\ttraining's RMSLE: 0.0911946\tvalid_1's l2: 0.0954064\tvalid_1's RMSLE: 0.102924\n",
      "[1060]\ttraining's l2: 0.0673656\ttraining's RMSLE: 0.0910551\tvalid_1's l2: 0.095291\tvalid_1's RMSLE: 0.102891\n",
      "[1070]\ttraining's l2: 0.0671562\ttraining's RMSLE: 0.0909539\tvalid_1's l2: 0.0952224\tvalid_1's RMSLE: 0.102876\n",
      "[1080]\ttraining's l2: 0.0668906\ttraining's RMSLE: 0.0907782\tvalid_1's l2: 0.0951311\tvalid_1's RMSLE: 0.102818\n",
      "[1090]\ttraining's l2: 0.0666685\ttraining's RMSLE: 0.0906697\tvalid_1's l2: 0.0950914\tvalid_1's RMSLE: 0.102828\n",
      "Early stopping, best iteration is:\n",
      "[1080]\ttraining's l2: 0.0668906\ttraining's RMSLE: 0.0907782\tvalid_1's l2: 0.0951311\tvalid_1's RMSLE: 0.102818\n",
      "predict valid for fold 3\n",
      "save model for fold 3\n",
      "start training for fold 4\n",
      "start training\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 8709, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 4.559508\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[10]\ttraining's l2: 1.85478\ttraining's RMSLE: 0.335832\tvalid_1's l2: 1.95715\tvalid_1's RMSLE: 0.351749\n",
      "[20]\ttraining's l2: 1.57778\ttraining's RMSLE: 0.316616\tvalid_1's l2: 1.66049\tvalid_1's RMSLE: 0.331704\n",
      "[30]\ttraining's l2: 1.34945\ttraining's RMSLE: 0.298949\tvalid_1's l2: 1.41744\tvalid_1's RMSLE: 0.313333\n",
      "[40]\ttraining's l2: 1.1606\ttraining's RMSLE: 0.282766\tvalid_1's l2: 1.21723\tvalid_1's RMSLE: 0.296542\n",
      "[50]\ttraining's l2: 1.00459\ttraining's RMSLE: 0.267967\tvalid_1's l2: 1.05212\tvalid_1's RMSLE: 0.281174\n",
      "[60]\ttraining's l2: 0.873505\ttraining's RMSLE: 0.254126\tvalid_1's l2: 0.913596\tvalid_1's RMSLE: 0.266817\n",
      "[70]\ttraining's l2: 0.764196\ttraining's RMSLE: 0.241365\tvalid_1's l2: 0.79874\tvalid_1's RMSLE: 0.253629\n",
      "[80]\ttraining's l2: 0.673114\ttraining's RMSLE: 0.22973\tvalid_1's l2: 0.70332\tvalid_1's RMSLE: 0.241616\n",
      "[90]\ttraining's l2: 0.597498\ttraining's RMSLE: 0.21932\tvalid_1's l2: 0.624946\tvalid_1's RMSLE: 0.230935\n",
      "[100]\ttraining's l2: 0.533035\ttraining's RMSLE: 0.209879\tvalid_1's l2: 0.558138\tvalid_1's RMSLE: 0.221226\n",
      "[110]\ttraining's l2: 0.478718\ttraining's RMSLE: 0.201137\tvalid_1's l2: 0.502087\tvalid_1's RMSLE: 0.212276\n",
      "[120]\ttraining's l2: 0.431899\ttraining's RMSLE: 0.192945\tvalid_1's l2: 0.454054\tvalid_1's RMSLE: 0.203915\n",
      "[130]\ttraining's l2: 0.392459\ttraining's RMSLE: 0.185553\tvalid_1's l2: 0.413905\tvalid_1's RMSLE: 0.196415\n",
      "[140]\ttraining's l2: 0.359489\ttraining's RMSLE: 0.178962\tvalid_1's l2: 0.380322\tvalid_1's RMSLE: 0.189749\n",
      "[150]\ttraining's l2: 0.329596\ttraining's RMSLE: 0.172902\tvalid_1's l2: 0.350326\tvalid_1's RMSLE: 0.183637\n",
      "[160]\ttraining's l2: 0.303016\ttraining's RMSLE: 0.167341\tvalid_1's l2: 0.323891\tvalid_1's RMSLE: 0.178085\n",
      "[170]\ttraining's l2: 0.279595\ttraining's RMSLE: 0.162159\tvalid_1's l2: 0.300242\tvalid_1's RMSLE: 0.172875\n",
      "[180]\ttraining's l2: 0.258832\ttraining's RMSLE: 0.157406\tvalid_1's l2: 0.27909\tvalid_1's RMSLE: 0.168083\n",
      "[190]\ttraining's l2: 0.24071\ttraining's RMSLE: 0.153049\tvalid_1's l2: 0.261013\tvalid_1's RMSLE: 0.163743\n",
      "[200]\ttraining's l2: 0.225267\ttraining's RMSLE: 0.149135\tvalid_1's l2: 0.245379\tvalid_1's RMSLE: 0.159824\n",
      "[210]\ttraining's l2: 0.211507\ttraining's RMSLE: 0.14539\tvalid_1's l2: 0.231524\tvalid_1's RMSLE: 0.156098\n",
      "[220]\ttraining's l2: 0.199328\ttraining's RMSLE: 0.142028\tvalid_1's l2: 0.21924\tvalid_1's RMSLE: 0.152713\n",
      "[230]\ttraining's l2: 0.189201\ttraining's RMSLE: 0.138847\tvalid_1's l2: 0.208933\tvalid_1's RMSLE: 0.149483\n",
      "[240]\ttraining's l2: 0.179867\ttraining's RMSLE: 0.136111\tvalid_1's l2: 0.199416\tvalid_1's RMSLE: 0.146679\n",
      "[250]\ttraining's l2: 0.171463\ttraining's RMSLE: 0.133439\tvalid_1's l2: 0.190817\tvalid_1's RMSLE: 0.143941\n",
      "[260]\ttraining's l2: 0.163986\ttraining's RMSLE: 0.13091\tvalid_1's l2: 0.183252\tvalid_1's RMSLE: 0.141353\n",
      "[270]\ttraining's l2: 0.157315\ttraining's RMSLE: 0.128768\tvalid_1's l2: 0.176714\tvalid_1's RMSLE: 0.139252\n",
      "[280]\ttraining's l2: 0.151135\ttraining's RMSLE: 0.126746\tvalid_1's l2: 0.170543\tvalid_1's RMSLE: 0.137262\n",
      "[290]\ttraining's l2: 0.145764\ttraining's RMSLE: 0.124929\tvalid_1's l2: 0.165198\tvalid_1's RMSLE: 0.135466\n",
      "[300]\ttraining's l2: 0.140689\ttraining's RMSLE: 0.123185\tvalid_1's l2: 0.160156\tvalid_1's RMSLE: 0.133723\n",
      "[310]\ttraining's l2: 0.136265\ttraining's RMSLE: 0.121545\tvalid_1's l2: 0.155964\tvalid_1's RMSLE: 0.13216\n",
      "[320]\ttraining's l2: 0.132485\ttraining's RMSLE: 0.120095\tvalid_1's l2: 0.152404\tvalid_1's RMSLE: 0.130799\n",
      "[330]\ttraining's l2: 0.128851\ttraining's RMSLE: 0.118679\tvalid_1's l2: 0.148956\tvalid_1's RMSLE: 0.129458\n",
      "[340]\ttraining's l2: 0.125438\ttraining's RMSLE: 0.117355\tvalid_1's l2: 0.145731\tvalid_1's RMSLE: 0.128211\n",
      "[350]\ttraining's l2: 0.122091\ttraining's RMSLE: 0.115932\tvalid_1's l2: 0.14257\tvalid_1's RMSLE: 0.126847\n",
      "[360]\ttraining's l2: 0.119067\ttraining's RMSLE: 0.114594\tvalid_1's l2: 0.139767\tvalid_1's RMSLE: 0.125575\n",
      "[370]\ttraining's l2: 0.115838\ttraining's RMSLE: 0.113379\tvalid_1's l2: 0.136624\tvalid_1's RMSLE: 0.124338\n",
      "[380]\ttraining's l2: 0.112891\ttraining's RMSLE: 0.1122\tvalid_1's l2: 0.13387\tvalid_1's RMSLE: 0.123151\n",
      "[390]\ttraining's l2: 0.11041\ttraining's RMSLE: 0.111126\tvalid_1's l2: 0.13162\tvalid_1's RMSLE: 0.122208\n",
      "[400]\ttraining's l2: 0.108555\ttraining's RMSLE: 0.110249\tvalid_1's l2: 0.13014\tvalid_1's RMSLE: 0.12158\n",
      "[410]\ttraining's l2: 0.106691\ttraining's RMSLE: 0.109428\tvalid_1's l2: 0.12847\tvalid_1's RMSLE: 0.120843\n",
      "[420]\ttraining's l2: 0.104879\ttraining's RMSLE: 0.108623\tvalid_1's l2: 0.126841\tvalid_1's RMSLE: 0.12016\n",
      "[430]\ttraining's l2: 0.103323\ttraining's RMSLE: 0.10792\tvalid_1's l2: 0.125559\tvalid_1's RMSLE: 0.119624\n",
      "[440]\ttraining's l2: 0.10176\ttraining's RMSLE: 0.107216\tvalid_1's l2: 0.124269\tvalid_1's RMSLE: 0.119096\n",
      "[450]\ttraining's l2: 0.100264\ttraining's RMSLE: 0.106574\tvalid_1's l2: 0.122921\tvalid_1's RMSLE: 0.118583\n",
      "[460]\ttraining's l2: 0.0990329\ttraining's RMSLE: 0.105962\tvalid_1's l2: 0.121975\tvalid_1's RMSLE: 0.118153\n",
      "[470]\ttraining's l2: 0.0975868\ttraining's RMSLE: 0.105326\tvalid_1's l2: 0.120755\tvalid_1's RMSLE: 0.117689\n",
      "[480]\ttraining's l2: 0.0963664\ttraining's RMSLE: 0.104759\tvalid_1's l2: 0.119805\tvalid_1's RMSLE: 0.117322\n",
      "[490]\ttraining's l2: 0.0951979\ttraining's RMSLE: 0.104221\tvalid_1's l2: 0.11888\tvalid_1's RMSLE: 0.116981\n",
      "[500]\ttraining's l2: 0.0940372\ttraining's RMSLE: 0.103691\tvalid_1's l2: 0.117901\tvalid_1's RMSLE: 0.116647\n",
      "[510]\ttraining's l2: 0.0929602\ttraining's RMSLE: 0.103195\tvalid_1's l2: 0.117039\tvalid_1's RMSLE: 0.116316\n",
      "[520]\ttraining's l2: 0.0920314\ttraining's RMSLE: 0.102744\tvalid_1's l2: 0.116369\tvalid_1's RMSLE: 0.116011\n",
      "[530]\ttraining's l2: 0.0910546\ttraining's RMSLE: 0.102318\tvalid_1's l2: 0.115564\tvalid_1's RMSLE: 0.115695\n",
      "[540]\ttraining's l2: 0.0901827\ttraining's RMSLE: 0.101847\tvalid_1's l2: 0.114941\tvalid_1's RMSLE: 0.115373\n",
      "[550]\ttraining's l2: 0.0892175\ttraining's RMSLE: 0.101354\tvalid_1's l2: 0.114212\tvalid_1's RMSLE: 0.115034\n",
      "[560]\ttraining's l2: 0.088206\ttraining's RMSLE: 0.100856\tvalid_1's l2: 0.113365\tvalid_1's RMSLE: 0.11469\n",
      "[570]\ttraining's l2: 0.0872703\ttraining's RMSLE: 0.100417\tvalid_1's l2: 0.112564\tvalid_1's RMSLE: 0.114394\n",
      "[580]\ttraining's l2: 0.0864661\ttraining's RMSLE: 0.10004\tvalid_1's l2: 0.11198\tvalid_1's RMSLE: 0.114193\n",
      "[590]\ttraining's l2: 0.0857529\ttraining's RMSLE: 0.0997419\tvalid_1's l2: 0.111449\tvalid_1's RMSLE: 0.114036\n",
      "[600]\ttraining's l2: 0.0850173\ttraining's RMSLE: 0.0994232\tvalid_1's l2: 0.110892\tvalid_1's RMSLE: 0.113877\n",
      "[610]\ttraining's l2: 0.0843154\ttraining's RMSLE: 0.0991061\tvalid_1's l2: 0.110355\tvalid_1's RMSLE: 0.113683\n",
      "[620]\ttraining's l2: 0.0837105\ttraining's RMSLE: 0.0988137\tvalid_1's l2: 0.109994\tvalid_1's RMSLE: 0.113555\n",
      "[630]\ttraining's l2: 0.0830264\ttraining's RMSLE: 0.0984785\tvalid_1's l2: 0.109457\tvalid_1's RMSLE: 0.11336\n",
      "[640]\ttraining's l2: 0.0823815\ttraining's RMSLE: 0.0981594\tvalid_1's l2: 0.108926\tvalid_1's RMSLE: 0.113157\n",
      "[650]\ttraining's l2: 0.0817792\ttraining's RMSLE: 0.0978973\tvalid_1's l2: 0.108469\tvalid_1's RMSLE: 0.113015\n",
      "[660]\ttraining's l2: 0.0811377\ttraining's RMSLE: 0.0975884\tvalid_1's l2: 0.10793\tvalid_1's RMSLE: 0.112808\n",
      "[670]\ttraining's l2: 0.0805537\ttraining's RMSLE: 0.0972759\tvalid_1's l2: 0.107518\tvalid_1's RMSLE: 0.112637\n",
      "[680]\ttraining's l2: 0.0799626\ttraining's RMSLE: 0.0969719\tvalid_1's l2: 0.107074\tvalid_1's RMSLE: 0.112487\n",
      "[690]\ttraining's l2: 0.0793972\ttraining's RMSLE: 0.0966705\tvalid_1's l2: 0.106662\tvalid_1's RMSLE: 0.112353\n",
      "[700]\ttraining's l2: 0.0788832\ttraining's RMSLE: 0.0963941\tvalid_1's l2: 0.106303\tvalid_1's RMSLE: 0.11222\n",
      "[710]\ttraining's l2: 0.0783241\ttraining's RMSLE: 0.0961268\tvalid_1's l2: 0.105941\tvalid_1's RMSLE: 0.112121\n",
      "[720]\ttraining's l2: 0.0777211\ttraining's RMSLE: 0.0957819\tvalid_1's l2: 0.105542\tvalid_1's RMSLE: 0.111959\n",
      "[730]\ttraining's l2: 0.0772074\ttraining's RMSLE: 0.095533\tvalid_1's l2: 0.105194\tvalid_1's RMSLE: 0.111847\n",
      "[740]\ttraining's l2: 0.0767405\ttraining's RMSLE: 0.09534\tvalid_1's l2: 0.10492\tvalid_1's RMSLE: 0.111781\n",
      "[750]\ttraining's l2: 0.0762304\ttraining's RMSLE: 0.095062\tvalid_1's l2: 0.104596\tvalid_1's RMSLE: 0.111644\n",
      "[760]\ttraining's l2: 0.0757851\ttraining's RMSLE: 0.0948289\tvalid_1's l2: 0.104413\tvalid_1's RMSLE: 0.111582\n",
      "[770]\ttraining's l2: 0.0753605\ttraining's RMSLE: 0.0946192\tvalid_1's l2: 0.104189\tvalid_1's RMSLE: 0.111478\n",
      "[780]\ttraining's l2: 0.0749472\ttraining's RMSLE: 0.0944263\tvalid_1's l2: 0.103929\tvalid_1's RMSLE: 0.111386\n",
      "[790]\ttraining's l2: 0.0745701\ttraining's RMSLE: 0.0942422\tvalid_1's l2: 0.103775\tvalid_1's RMSLE: 0.11132\n",
      "[800]\ttraining's l2: 0.0741608\ttraining's RMSLE: 0.0940478\tvalid_1's l2: 0.103459\tvalid_1's RMSLE: 0.111213\n",
      "[810]\ttraining's l2: 0.0737591\ttraining's RMSLE: 0.093839\tvalid_1's l2: 0.103193\tvalid_1's RMSLE: 0.111121\n",
      "[820]\ttraining's l2: 0.0734018\ttraining's RMSLE: 0.0936667\tvalid_1's l2: 0.102951\tvalid_1's RMSLE: 0.111055\n",
      "[830]\ttraining's l2: 0.073068\ttraining's RMSLE: 0.0934964\tvalid_1's l2: 0.102753\tvalid_1's RMSLE: 0.110969\n",
      "[840]\ttraining's l2: 0.0727373\ttraining's RMSLE: 0.0933264\tvalid_1's l2: 0.102597\tvalid_1's RMSLE: 0.110898\n",
      "[850]\ttraining's l2: 0.072399\ttraining's RMSLE: 0.0931659\tvalid_1's l2: 0.102405\tvalid_1's RMSLE: 0.110829\n",
      "[860]\ttraining's l2: 0.0720968\ttraining's RMSLE: 0.0930127\tvalid_1's l2: 0.102281\tvalid_1's RMSLE: 0.110783\n",
      "[870]\ttraining's l2: 0.071796\ttraining's RMSLE: 0.092825\tvalid_1's l2: 0.102119\tvalid_1's RMSLE: 0.110684\n",
      "[880]\ttraining's l2: 0.0714751\ttraining's RMSLE: 0.0926695\tvalid_1's l2: 0.102025\tvalid_1's RMSLE: 0.110678\n",
      "[890]\ttraining's l2: 0.0711367\ttraining's RMSLE: 0.092436\tvalid_1's l2: 0.101787\tvalid_1's RMSLE: 0.110518\n",
      "[900]\ttraining's l2: 0.0708441\ttraining's RMSLE: 0.0922886\tvalid_1's l2: 0.101664\tvalid_1's RMSLE: 0.11049\n",
      "[910]\ttraining's l2: 0.0705496\ttraining's RMSLE: 0.0921064\tvalid_1's l2: 0.101537\tvalid_1's RMSLE: 0.11043\n",
      "[920]\ttraining's l2: 0.0702693\ttraining's RMSLE: 0.0919448\tvalid_1's l2: 0.101411\tvalid_1's RMSLE: 0.110393\n",
      "[930]\ttraining's l2: 0.0699432\ttraining's RMSLE: 0.0917665\tvalid_1's l2: 0.101291\tvalid_1's RMSLE: 0.110381\n",
      "[940]\ttraining's l2: 0.0696296\ttraining's RMSLE: 0.0915889\tvalid_1's l2: 0.101161\tvalid_1's RMSLE: 0.110349\n",
      "[950]\ttraining's l2: 0.0693808\ttraining's RMSLE: 0.0914591\tvalid_1's l2: 0.101065\tvalid_1's RMSLE: 0.110328\n",
      "[960]\ttraining's l2: 0.0690874\ttraining's RMSLE: 0.0912982\tvalid_1's l2: 0.100954\tvalid_1's RMSLE: 0.110334\n",
      "Early stopping, best iteration is:\n",
      "[957]\ttraining's l2: 0.0691754\ttraining's RMSLE: 0.0913564\tvalid_1's l2: 0.100984\tvalid_1's RMSLE: 0.110323\n",
      "predict valid for fold 4\n",
      "save model for fold 4\n",
      "RMSLE: 0.28487622196889606\n"
     ]
    }
   ],
   "source": [
    "model_path = Path(\"../output/model004\")\n",
    "\n",
    "train_rmsle = train(train_df, model_path)\n",
    "print(f\"RMSLE: {train_rmsle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, model_path):\n",
    "    predictions = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"loading model for fold {fold}\")\n",
    "        model = lgb.Booster(model_file=model_path / f\"model_fold{fold+1:03d}.bin\")\n",
    "\n",
    "        print(f\"start evaluate for fold {fold}\")\n",
    "        X_test = df.copy()\n",
    "\n",
    "        print(f\"predict test for fold {fold}\")\n",
    "        y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        y_pred = np.clip(y_pred, 0, None)\n",
    "        y_pred = np.exp(y_pred)\n",
    "        predictions.append(y_pred)\n",
    "    \n",
    "    average_predictions = np.mean(predictions, axis=0)\n",
    "    return average_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model for fold 0\n",
      "start evaluate for fold 0\n",
      "predict test for fold 0\n",
      "loading model for fold 1\n",
      "start evaluate for fold 1\n",
      "predict test for fold 1\n",
      "loading model for fold 2\n",
      "start evaluate for fold 2\n",
      "predict test for fold 2\n",
      "loading model for fold 3\n",
      "start evaluate for fold 3\n",
      "predict test for fold 3\n",
      "loading model for fold 4\n",
      "start evaluate for fold 4\n",
      "predict test for fold 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  9.60914966,   4.96354999,   3.22738031, ..., 130.68454038,\n",
       "        94.20444331,  58.3059777 ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = evaluate(test_df, model_path)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(input_path / \"sampleSubmission.csv\")\n",
    "submission[\"count\"] = y_pred\n",
    "submission.to_csv(\"../output/submission004.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = lgb.Booster(model_file=model_path / f\"model_fold001.bin\")\n",
    "importance_df = pd.DataFrame()\n",
    "\n",
    "importance_df[\"importance\"] = model.feature_importance(importance_type=\"gain\")\n",
    "importance_df[\"feature_name\"] = model.feature_name()\n",
    "importance_df = importance_df.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 10))\n",
    "sns.barplot(data=importance_df, x=\"importance\", y=\"feature_name\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
